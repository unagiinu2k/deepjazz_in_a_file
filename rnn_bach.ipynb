{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git commit -a -m \"checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.rileynwong.com/blog/2019/2/25/generating-music-with-an-lstm-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparation I wrote  (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(l, n):\n",
    "    \"\"\"\n",
    "    リストをサブリストに分割する\n",
    "    :param l: リスト\n",
    "    :param n: サブリストの要素数\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    for idx in range(0, len(l), n):\n",
    "        yield l[idx:idx + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chorales/midi/028100b_.mid\n",
      "chorales/midi/026100b_.mid\n",
      "chorales/midi/028700b_.mid\n",
      "chorales/midi/032200b_.mid\n",
      "chorales/midi/065900b_.mid\n",
      "chorales/midi/061500b_.mid\n",
      "chorales/midi/006906b_.mid\n",
      "chorales/midi/012008ba.mid\n",
      "chorales/midi/001707b_.mid\n",
      "chorales/midi/016206blpz.mid\n",
      "chorales/midi/014004b_.mid\n",
      "chorales/midi/069100b_.mid\n",
      "chorales/midi/009005b_.mid\n",
      "chorales/midi/070000b_.mid\n",
      "chorales/midi/065200b_.mid\n",
      "chorales/midi/009801b_.mid\n",
      "chorales/midi/069400b_.mid\n",
      "chorales/midi/037700b_.mid\n",
      "chorales/midi/033000b_.mid\n",
      "chorales/midi/034200b_.mid\n",
      "chorales/midi/005708b_.mid\n",
      "chorales/midi/041600b_.mid\n",
      "chorales/midi/037500b_.mid\n",
      "chorales/midi/039800b_.mid\n",
      "chorales/midi/038300b_.mid\n",
      "chorales/midi/027200b_.mid\n",
      "chorales/midi/040200b_.mid\n",
      "chorales/midi/012406b_.mid\n",
      "chorales/midi/010602b_.mid\n",
      "chorales/midi/008606b_.mid\n",
      "chorales/midi/004003b_.mid\n",
      "chorales/midi/007607b_.mid\n",
      "chorales/midi/013806b_.mid\n",
      "chorales/midi/016106b_.mid\n",
      "chorales/midi/013701b_.mid\n",
      "chorales/midi/010806b_.mid\n",
      "chorales/midi/024437b_.mid\n",
      "chorales/midi/033600b_.mid\n",
      "chorales/midi/033200b_.mid\n",
      "chorales/midi/006206b_.mid\n",
      "chorales/midi/005505b_.mid\n",
      "chorales/midi/019007binst.mid\n",
      "chorales/midi/030600b_.mid\n",
      "chorales/midi/006906ba.mid\n",
      "chorales/midi/012606b_.mid\n",
      "chorales/midi/039000b_.mid\n",
      "chorales/midi/066300b_.mid\n",
      "chorales/midi/038500b_.mid\n",
      "chorales/midi/036600b_.mid\n",
      "chorales/midi/014505b_.mid\n",
      "chorales/midi/024454b_.mid\n",
      "chorales/midi/036100b_.mid\n",
      "chorales/midi/013703b_.mid\n",
      "chorales/midi/070100b_.mid\n",
      "chorales/midi/024809b1.mid\n",
      "chorales/midi/015403b_.mid\n",
      "chorales/midi/024526b_.mid\n",
      "chorales/midi/006005b_.mid\n",
      "chorales/midi/009207b_.mid\n",
      "chorales/midi/039600b_.mid\n",
      "chorales/midi/035400b_.mid\n",
      "chorales/midi/026800b_.mid\n",
      "chorales/midi/000408b_.mid\n",
      "chorales/midi/026000b_.mid\n",
      "chorales/midi/002506b_.mid\n",
      "chorales/midi/029700b_.mid\n",
      "chorales/midi/037800b_.mid\n",
      "chorales/midi/031100b_.mid\n",
      "chorales/midi/013506b_.mid\n",
      "chorales/midi/035300b_.mid\n",
      "chorales/midi/004803b_.mid\n",
      "chorales/midi/017405b_.mid\n",
      "chorales/midi/037400b_.mid\n",
      "chorales/midi/000707b_.mid\n",
      "chorales/midi/010107b_.mid\n",
      "chorales/midi/008807b_.mid\n",
      "chorales/midi/014907b_.mid\n",
      "chorales/midi/000507b_.mid\n",
      "chorales/midi/024440b_.mid\n",
      "chorales/midi/026700b_.mid\n",
      "chorales/midi/042600b_.mid\n",
      "chorales/midi/064600b_.mid\n",
      "chorales/midi/024432b_.mid\n",
      "chorales/midi/015705b_.mid\n",
      "chorales/midi/029500b_.mid\n",
      "chorales/midi/003306b_.mid\n",
      "chorales/midi/007706b_.mid\n",
      "chorales/midi/039100b_.mid\n",
      "chorales/midi/003706b_.mid\n",
      "chorales/midi/040500b_.mid\n",
      "chorales/midi/037900b_.mid\n",
      "chorales/midi/014608b_.mid\n",
      "chorales/midi/004106b_.mid\n",
      "chorales/midi/028600b_.mid\n",
      "chorales/midi/030200b_.mid\n",
      "chorales/midi/005605b_.mid\n",
      "chorales/midi/076904b_.mid\n",
      "chorales/midi/076905b_.mid\n",
      "chorales/midi/019506b_.mid\n",
      "chorales/midi/001805bw.mid\n",
      "chorales/midi/011407b_.mid\n",
      "chorales/midi/000907b_.mid\n",
      "chorales/midi/011704b_.mid\n",
      "chorales/midi/007614b_.mid\n",
      "chorales/midi/038700b_.mid\n",
      "chorales/midi/073300b_.mid\n",
      "chorales/midi/042900b_.mid\n",
      "chorales/midi/014007b_.mid\n",
      "chorales/midi/024444b_.mid\n",
      "chorales/midi/009709b_.mid\n",
      "chorales/midi/024417b_.mid\n",
      "chorales/midi/002007b_.mid\n",
      "chorales/midi/024823bs.mid\n",
      "chorales/midi/035900b_.mid\n",
      "chorales/midi/035000b_.mid\n",
      "chorales/midi/064900b_.mid\n",
      "chorales/midi/003608b2.mid\n",
      "chorales/midi/065000t.mid\n",
      "chorales/midi/012206b_.mid\n",
      "chorales/midi/017807b_.mid\n",
      "chorales/midi/043100b_.mid\n",
      "chorales/midi/038100b_.mid\n",
      "chorales/midi/040700b_.mid\n",
      "chorales/midi/018806b_.mid\n",
      "chorales/midi/109100b_.mid\n",
      "chorales/midi/032000b_.mid\n",
      "chorales/midi/006404b_.mid\n",
      "chorales/midi/030100b_.mid\n",
      "chorales/midi/034000b_.mid\n",
      "chorales/midi/015105b_.mid\n",
      "chorales/midi/038200b_.mid\n",
      "chorales/midi/065100b_.mid\n",
      "chorales/midi/008107b_.mid\n",
      "chorales/midi/009906b_.mid\n",
      "chorales/midi/032700b_.mid\n",
      "chorales/midi/015804b_.mid\n",
      "chorales/midi/031800b_.mid\n",
      "chorales/midi/042100b_.mid\n",
      "chorales/midi/024833b3.mid\n",
      "chorales/midi/014406b_.mid\n",
      "chorales/midi/009709ch.mid\n",
      "chorales/midi/008506b_.mid\n",
      "chorales/midi/011308b_.mid\n",
      "chorales/midi/043600b_.mid\n",
      "chorales/midi/016806b_.mid\n",
      "chorales/midi/031000b_.mid\n",
      "chorales/midi/007011b_.mid\n",
      "chorales/midi/043500b_.mid\n",
      "chorales/midi/009106b_.mid\n",
      "chorales/midi/030700b_.mid\n",
      "chorales/midi/032900b_.mid\n",
      "chorales/midi/013606b_.mid\n",
      "chorales/midi/066200b_.mid\n",
      "chorales/midi/034300b_.mid\n",
      "chorales/midi/027300b_.mid\n",
      "chorales/midi/025100b_.mid\n",
      "chorales/midi/028300b_.mid\n",
      "chorales/midi/043800B_.mid\n",
      "chorales/midi/031400b_.mid\n",
      "chorales/midi/066700b_.mid\n",
      "chorales/midi/064800b_.mid\n",
      "chorales/midi/014710b_.mid\n",
      "chorales/midi/024828b3.mid\n",
      "chorales/midi/024853b5.mid\n",
      "chorales/midi/017206ch.mid\n",
      "chorales/midi/016907b_.mid\n",
      "chorales/midi/004606b_.mid\n",
      "chorales/midi/003604b2.mid\n",
      "chorales/midi/024842b4.mid\n",
      "chorales/midi/029600b_.mid\n",
      "chorales/midi/024528b_.mid\n",
      "chorales/midi/007903b_.mid\n",
      "chorales/midi/001106b_.mid\n",
      "chorales/midi/hallelujah.mid\n",
      "chorales/midi/032400b_.mid\n",
      "chorales/midi/066600b_.mid\n",
      "chorales/midi/027100b_.mid\n",
      "chorales/midi/060800b_.mid\n",
      "chorales/midi/065500b_.mid\n",
      "chorales/midi/024859b6.mid\n",
      "chorales/midi/027500b_.mid\n",
      "chorales/midi/019007b_.mid\n",
      "chorales/midi/043400b_.mid\n",
      "chorales/midi/024429ba.mid\n",
      "chorales/midi/008906b_.mid\n",
      "chorales/midi/038900b_.mid\n",
      "chorales/midi/009507b_.mid\n",
      "chorales/midi/031500b_.mid\n",
      "chorales/midi/001405b_.mid\n",
      "chorales/midi/040000b_.mid\n",
      "chorales/midi/012306b_.mid\n",
      "chorales/midi/017705b_.mid\n",
      "chorales/midi/042400b_.mid\n",
      "chorales/midi/002806b_.mid\n",
      "chorales/midi/042800b_.mid\n",
      "chorales/midi/066100b_.mid\n",
      "chorales/midi/006408b_.mid\n",
      "chorales/midi/111800b_.mid\n",
      "chorales/midi/007007b_.mid\n",
      "chorales/midi/001606b_.mid\n",
      "chorales/midi/035800b_.mid\n",
      "chorales/midi/026500b_.mid\n",
      "chorales/midi/024864b6.mid\n",
      "chorales/midi/002706b_.mid\n",
      "chorales/midi/037600b_.mid\n",
      "chorales/midi/025500b_.mid\n",
      "chorales/midi/001907b_.mid\n",
      "chorales/midi/016506b_.mid\n",
      "chorales/midi/036700b_.mid\n",
      "chorales/midi/019412b_.mid\n",
      "chorales/midi/000101b_.mid\n",
      "chorales/midi/009209b_.mid\n",
      "chorales/midi/001805blz.mid\n",
      "chorales/midi/011506b_.mid\n",
      "chorales/midi/022902b_.mid\n",
      "chorales/midi/013006b_.mid\n",
      "chorales/midi/010406b_.mid\n",
      "chorales/midi/026700ba.mid\n",
      "chorales/midi/024864bs.mid\n",
      "chorales/midi/030000b_.mid\n",
      "chorales/midi/041800b_.mid\n",
      "chorales/midi/006502b_.mid\n",
      "chorales/midi/022711b_.mid\n",
      "chorales/midi/041400b_.mid\n",
      "chorales/midi/031900b_.mid\n",
      "chorales/midi/019710b_.mid\n",
      "chorales/midi/013705ch.mid\n",
      "chorales/midi/031200b_.mid\n",
      "chorales/midi/000806b_.mid\n",
      "chorales/midi/035600b_.mid\n",
      "chorales/midi/012106b_.mid\n",
      "chorales/midi/039700b_.mid\n",
      "chorales/midi/019707ba.mid\n",
      "chorales/midi/022703b_.mid\n",
      "chorales/midi/024517b_.mid\n",
      "chorales/midi/002908ch.mid\n",
      "chorales/midi/014403b_.mid\n",
      "chorales/midi/033400b_.mid\n",
      "chorales/midi/013306b_.mid\n",
      "chorales/midi/024835b3.mid\n",
      "chorales/midi/024842bs.mid\n",
      "chorales/midi/042200b_.mid\n",
      "chorales/midi/039900b_.mid\n",
      "chorales/midi/004606bs.mid\n",
      "chorales/midi/025300b_.mid\n",
      "chorales/midi/024410b_.mid\n",
      "chorales/midi/028500b_.mid\n",
      "chorales/midi/024446b_.mid\n",
      "chorales/midi/042300b_.mid\n",
      "chorales/midi/013906b_.mid\n",
      "chorales/midi/065700b_.mid\n",
      "chorales/midi/028000b_.mid\n",
      "chorales/midi/025600b_.mid\n",
      "chorales/midi/076903b_.mid\n",
      "chorales/midi/004106bs.mid\n",
      "chorales/midi/029400b_.mid\n",
      "chorales/midi/039400b_.mid\n",
      "chorales/midi/025400b_.mid\n",
      "chorales/midi/011606b_.mid\n",
      "chorales/midi/065300b_.mid\n",
      "chorales/midi/004207b_.mid\n",
      "chorales/midi/010707b_.mid\n",
      "chorales/midi/000504b_.mid\n",
      "chorales/midi/040100b_.mid\n",
      "chorales/midi/035100b_.mid\n",
      "chorales/midi/033700b_.mid\n",
      "chorales/midi/036400b_.mid\n",
      "chorales/midi/022707b_.mid\n",
      "chorales/midi/069100orn.mid\n",
      "chorales/midi/002011b_.mid\n",
      "chorales/midi/036000b_.mid\n",
      "chorales/midi/041200b_.mid\n",
      "chorales/midi/043000b_.mid\n",
      "chorales/midi/012905b_.mid\n",
      "chorales/midi/039500b_.mid\n",
      "chorales/midi/039200b_.mid\n",
      "chorales/midi/066000b_.mid\n",
      "chorales/midi/066400b_.mid\n",
      "chorales/midi/041700b_.mid\n",
      "chorales/midi/026400b_.mid\n",
      "chorales/midi/024462b_.mid\n",
      "chorales/midi/017106b_.mid\n",
      "chorales/midi/028900b_.mid\n",
      "chorales/midi/003806b_.mid\n",
      "chorales/midi/036500B_.mid\n",
      "chorales/midi/032500b_.mid\n",
      "chorales/midi/060600b_.mid\n",
      "chorales/midi/032300b_.mid\n",
      "chorales/midi/010006b_.mid\n",
      "chorales/midi/024511b_.mid\n",
      "chorales/midi/013704b_.mid\n",
      "chorales/midi/014706b_.mid\n",
      "chorales/midi/010207b_.mid\n",
      "chorales/midi/019406b_.mid\n",
      "chorales/midi/032600b_.mid\n",
      "chorales/midi/018405b_.mid\n",
      "chorales/midi/030300b_.mid\n",
      "chorales/midi/076902b_.mid\n",
      "chorales/midi/014500ba.mid\n",
      "chorales/midi/030800b_.mid\n",
      "chorales/midi/032100b_.mid\n",
      "chorales/midi/026600b_.mid\n",
      "chorales/midi/064700b_.mid\n",
      "chorales/midi/006606b_.mid\n",
      "chorales/midi/041500b_.mid\n",
      "chorales/midi/009307b_.mid\n",
      "chorales/midi/024425b_.mid\n",
      "chorales/midi/034800b_.mid\n",
      "chorales/midi/037200b_.mid\n",
      "chorales/midi/027600b_.mid\n",
      "chorales/midi/006704b_.mid\n",
      "chorales/midi/007903bs.mid\n",
      "chorales/midi/010506b_.mid\n",
      "chorales/midi/024505b_.mid\n",
      "chorales/midi/013705b_.mid\n",
      "chorales/midi/005206b_.mid\n",
      "chorales/midi/035500b_.mid\n",
      "chorales/midi/004507b_.mid\n",
      "chorales/midi/029900b_.mid\n",
      "chorales/midi/024522b_.mid\n",
      "chorales/midi/066500b_.mid\n",
      "chorales/midi/025200b_.mid\n",
      "chorales/midi/038600b_.mid\n",
      "chorales/midi/036800b_.mid\n",
      "chorales/midi/041900B_.mid\n",
      "chorales/midi/017606b_.mid\n",
      "chorales/midi/024805b1.mid\n",
      "chorales/midi/043300b_.mid\n",
      "chorales/midi/030500b_.mid\n",
      "chorales/midi/033800b_.mid\n",
      "chorales/midi/065400b_.mid\n",
      "chorales/midi/038800b_.mid\n",
      "chorales/midi/017206vn.mid\n",
      "chorales/midi/012506b_.mid\n",
      "chorales/midi/043700B_.mid\n",
      "chorales/midi/006106b_.mid\n",
      "chorales/midi/011709b_.mid\n",
      "chorales/midi/029100b_.mid\n",
      "chorales/midi/076901b_.mid\n",
      "chorales/midi/024515b_.mid\n",
      "chorales/midi/004705b_.mid\n",
      "chorales/midi/001907ch.mid\n",
      "chorales/midi/012805b_.mid\n",
      "chorales/midi/000206b_.mid\n",
      "chorales/midi/040300b_.mid\n",
      "chorales/midi/005903b_.mid\n",
      "chorales/midi/034700b_.mid\n",
      "chorales/midi/041300b_.mid\n",
      "chorales/midi/034500b_.mid\n",
      "chorales/midi/029200b_.mid\n",
      "chorales/midi/011909b_.mid\n",
      "chorales/midi/024537b_.mid\n",
      "chorales/midi/026200b_.mid\n",
      "chorales/midi/037300bv.mid\n",
      "chorales/midi/002406b_.mid\n",
      "chorales/midi/007206b_.mid\n",
      "chorales/midi/037000b_.mid\n",
      "chorales/midi/036300b_.mid\n",
      "chorales/midi/024503b_.mid\n",
      "chorales/midi/035700b_.mid\n",
      "chorales/midi/037300b_.mid\n",
      "chorales/midi/031600b_.mid\n",
      "chorales/midi/006507b_.mid\n",
      "chorales/midi/000106trio.mid\n",
      "chorales/midi/034600b_.mid\n",
      "chorales/midi/009408b_.mid\n",
      "chorales/midi/066800com.mid\n",
      "chorales/midi/002908b_.mid\n",
      "chorales/midi/018707b_.mid\n",
      "chorales/midi/016406b_.mid\n",
      "chorales/midi/007507b_.mid\n",
      "chorales/midi/007011ch.mid\n",
      "chorales/midi/025800b_.mid\n",
      "chorales/midi/017507ch.mid\n",
      "chorales/midi/032800b_.mid\n",
      "chorales/midi/040900b_.mid\n",
      "chorales/midi/002606b_.mid\n",
      "chorales/midi/029300b_.mid\n",
      "chorales/midi/006402b_.mid\n",
      "chorales/midi/065800b_.mid\n",
      "chorales/midi/018305b_.mid\n",
      "chorales/midi/007906b_.mid\n",
      "chorales/midi/033300b_.mid\n",
      "chorales/midi/003109b_.mid\n",
      "chorales/midi/028400b_.mid\n",
      "chorales/midi/012705b_.mid\n",
      "chorales/midi/036200b_.mid\n",
      "chorales/midi/000306b_.mid\n",
      "chorales/midi/001207b_.mid\n",
      "chorales/midi/033100b_.mid\n",
      "chorales/midi/034400b_.mid\n",
      "chorales/midi/015505b_.mid\n",
      "chorales/midi/026900b_.mid\n",
      "chorales/midi/024415b_.mid\n",
      "chorales/midi/040800b_.mid\n",
      "chorales/midi/030400b_.mid\n",
      "chorales/midi/041100B_.mid\n",
      "chorales/midi/034100b_.mid\n",
      "chorales/midi/000606b_.mid\n",
      "chorales/midi/028800b_.mid\n",
      "chorales/midi/008008b_.mid\n",
      "chorales/midi/024540b_.mid\n",
      "chorales/midi/016606b_.mid\n",
      "chorales/midi/015606b_.mid\n",
      "chorales/midi/041000b_.mid\n",
      "chorales/midi/069000b_.mid\n",
      "chorales/midi/007408b_.mid\n",
      "chorales/midi/017206b_.mid\n",
      "chorales/midi/037100b_.mid\n",
      "chorales/midi/011007b_.mid\n",
      "chorales/midi/033900b_.mid\n",
      "chorales/midi/015309b_.mid\n",
      "chorales/midi/035200b_.mid\n",
      "chorales/midi/018405unk.mid\n",
      "chorales/midi/064500b_.mid\n",
      "chorales/midi/024817b2.mid\n",
      "chorales/midi/006707b_.mid\n",
      "chorales/midi/051000b_.mid\n",
      "chorales/midi/027400b_.mid\n",
      "chorales/midi/022709b_.mid\n",
      "chorales/midi/014806b_.mid\n",
      "chorales/midi/040900bv.mid\n",
      "chorales/midi/000106b_.mid\n",
      "chorales/midi/009106ch.mid\n",
      "chorales/midi/004006b_.mid\n",
      "chorales/midi/043200b_.mid\n",
      "chorales/midi/025000b_.mid\n",
      "chorales/midi/029800b_.mid\n",
      "chorales/midi/027700b_.mid\n",
      "chorales/midi/073800b_.mid\n",
      "chorales/midi/065000b_.mid\n",
      "chorales/midi/003206b_.mid\n",
      "chorales/midi/024403b_.mid\n",
      "chorales/midi/007514b_.mid\n",
      "chorales/midi/022701b_.mid\n",
      "chorales/midi/004407b_.mid\n",
      "chorales/midi/027000b_.mid\n",
      "chorales/midi/040600b_.mid\n",
      "chorales/midi/034900b_.mid\n",
      "chorales/midi/015905b_.mid\n",
      "chorales/midi/042000b_.mid\n",
      "chorales/midi/010306b_.mid\n",
      "chorales/midi/001007b_.mid\n",
      "chorales/midi/042500b_.mid\n",
      "chorales/midi/040400b_.mid\n",
      "chorales/midi/027800b_.mid\n",
      "chorales/midi/029000b_.mid\n",
      "chorales/midi/024809bs.mid\n",
      "chorales/midi/000603b_.mid\n",
      "chorales/midi/039300b_.mid\n",
      "chorales/midi/014907ch.mid\n",
      "chorales/midi/015305b_.mid\n",
      "chorales/midi/031700b_.mid\n",
      "chorales/midi/065600b_.mid\n",
      "chorales/midi/009606b_.mid\n",
      "chorales/midi/008707b_.mid\n",
      "chorales/midi/022602b_.mid\n",
      "chorales/midi/011205b_.mid\n",
      "chorales/midi/013702b_.mid\n",
      "chorales/midi/015408b_.mid\n",
      "chorales/midi/008405b_.mid\n",
      "chorales/midi/008305b_.mid\n",
      "chorales/midi/007807b_.mid\n",
      "chorales/midi/014001b_.mid\n",
      "chorales/midi/024823b2.mid\n",
      "chorales/midi/024846b5.mid\n",
      "chorales/midi/017906b_.mid\n",
      "chorales/midi/003006b_.mid\n",
      "chorales/midi/017507b_.mid\n",
      "chorales/midi/038400b_.mid\n",
      "chorales/midi/031300b_.mid\n",
      "chorales/midi/019705b_.mid\n",
      "chorales/midi/011106b_.mid\n",
      "chorales/midi/004311b_.mid\n",
      "chorales/midi/026300b_.mid\n",
      "chorales/midi/030900b_.mid\n",
      "chorales/midi/025900b_.mid\n",
      "chorales/midi/004008b_.mid\n",
      "chorales/midi/024514b_.mid\n",
      "chorales/midi/027900b_.mid\n",
      "chorales/midi/024812b2.mid\n",
      "chorales/midi/012006b_.mid\n",
      "chorales/midi/028200b_.mid\n",
      "chorales/midi/038000b_.mid\n",
      "chorales/midi/066800b_.mid\n",
      "chorales/midi/024310b_.mid\n",
      "chorales/midi/025700b_.mid\n",
      "chorales/midi/018007b_.mid\n",
      "chorales/midi/018506b_.mid\n",
      "chorales/midi/015301b_.mid\n",
      "chorales/midi/007305b_.mid\n",
      "chorales/midi/042700b_.mid\n",
      "chorales/midi/003907b_.mid\n",
      "chorales/midi/036900b_.mid\n",
      "chorales/midi/004807b_.mid\n",
      "chorales/midi/064200b_.mid\n",
      "chorales/midi/033500b_.mid\n",
      "chorales/midi/001306b_.mid\n"
     ]
    }
   ],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "notes_list = []\n",
    "note_set = set()\n",
    "for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "    run_notes = []\n",
    "    print(file)\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    if parts: # file has instrument parts\n",
    "        #Pdb().set_trace()\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            run_notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            #Pdb().set_trace()\n",
    "            run_notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    note_set = note_set | set(run_notes)\n",
    "    for n in split_list(run_notes , max_sequence_length):\n",
    "        if len(n) > 10:\n",
    "            notes_list.append(n)\n",
    "    #notes_list.append(run_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to be ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as in tutorial on the web (to be skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "notes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "notes = []\n",
    "for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "    print(file)\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    if parts: # file has instrument parts\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example : when there is only one midi file (to be skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"midi/sonate_31.mid\"\n",
    "\n",
    "midi = converter.parse(file)\n",
    "notes_to_parse = None\n",
    "parts = instrument.partitionByInstrument(midi)\n",
    "if parts: # file has instrument parts\n",
    "    notes_to_parse = parts.parts[0].recurse()\n",
    "else: # file has notes in a flat structure\n",
    "    notes_to_parse = midi.flat.notes\n",
    "for element in notes_to_parse:\n",
    "    if isinstance(element, note.Note):\n",
    "        notes.append(str(element.pitch))\n",
    "    elif isinstance(element, chord.Chord):\n",
    "        notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_list = [x for x in notes_to_parse if isinstance(x , note.Note)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(note_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note = note_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(a_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding new flow (main)\n",
    "\n",
    "https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
    "に概ね準拠仕様と思ったが・・・\n",
    "\n",
    "- そもそもlabelencoder -> onehot  は今後必要ないよとwarning が出る\n",
    "- onehot の挙動が読みにくい\n",
    "\n",
    "のでlabelencodingしたあと直にnp.arrayをmanual onehote化したほうがいいのではないか？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(list(note_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_notes_list = [le.transform(np.array(x)) for x in notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set(le.transform(list(note_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = [torch.zeros(labeled_notes_list[i].shape[0] - 1 , len(label_set)) for i in range(len(notes_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(notes_list)):\n",
    "    for j in range(labeled_notes_list[i].shape[0]-1):\n",
    "        raw_X[i][j , labeled_notes_list[i][j]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_X = torch.nn.utils.rnn.pack_sequence(raw_X , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X = torch.nn.utils.rnn.pad_packed_sequence(packed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_y = [torch.tensor(np.array(x[1:])) for x in labeled_notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_y = torch.nn.utils.rnn.pack_sequence(raw_y , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_y = torch.nn.utils.rnn.pad_packed_sequence(packed_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding previous flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohnotes = ohe.fit_transform(np.array(notes).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohnotes = ohe.fit(np.array(list(note_set)).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohnotes_list = [ohe.transform(np.array(x).reshape(-1,1)) for x in notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ohnotes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = [torch.Tensor(x.toarray()) for x in ohnotes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_X = torch.nn.utils.rnn.pack_sequence(raw_X , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X = torch.nn.utils.rnn.pad_packed_sequence(packed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference\n",
    "\n",
    "- OneHotEncoderだけでいける。LabelEncoderをかます必要なしと当初思っていたがむしろ逆\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n",
    "\n",
    "Another possible good reference:\n",
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obsolete : label encoder: 不必要という判断になっていたが結局こちらのほうがいいかも？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(list(note_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inotes = le.transform(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inotes[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.Tensor([len(x) - 1 for x in notes_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ppd_X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM\n",
    "\n",
    "参考文献のpreprocessはあまり納得いかないので・・\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "をみつつやってみるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  復習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "sequence_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(sequence_length, sequence_num, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(num_layers , sequence_num , hidden_size)\n",
    "c0 = torch.randn(num_layers , sequence_num, hidden_size)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputの最後尾（sequence length方向の末尾）とhnは一致する:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 復習２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = ppd_X[0][: , 0:10 ]\n",
    "batch_y = ppd_y[0][:,  0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_num = batch_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(num_layers , sequence_num , hidden_size)\n",
    "c0 = torch.randn(num_layers , sequence_num, hidden_size)\n",
    "output, (hn, cn) = rnn(batch_X, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_size = len(ohe.get_feature_names())\n",
    "hidden_size = 50\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ppd_X[0].shape[2]\n",
    "hidden_size = ppd_X[0].shape[2]\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(my_model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
    "\n",
    "        #self.linear = nn.Linear(hidden_size, input_size) #output dimension has to be identical with the input dimension\n",
    "        #self.softmax = nn.functional.softmax()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        sequence_num = input.shape[1]\n",
    "        self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input, (self.h0, self.c0))\n",
    "        #y = self.linear(y)\n",
    "        y = nn.functional.softmax(y , dim = 2)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献に似せたモデル\n",
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "に似せたモデル\n",
    "現状ランダムの1.8倍程度の正答率にしかならない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ppd_X[0].shape[2]\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers , dropout):\n",
    "        #super(my_model, self).__init__()\n",
    "        \n",
    "        super().__init__()\n",
    "        #self.input_size = input_size\n",
    "        #self.hidden_size = hidden_size\n",
    "        #self.num_layers = num_layers\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers , dropout=dropout)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, input_size) #output dimension has to be identical with the input dimension\n",
    "        \n",
    "        \n",
    "        self.sm = nn.Softmax(dim = 2)\n",
    "      \n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        #self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        #self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input)#, (self.h0, self.c0))\n",
    "        y = self.linear(y)\n",
    "        y = self.relu1(y)\n",
    "        #y = nn.functional.softmax(y , dim = 2)\n",
    "        y = self.sm(y)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers , dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp = model.forward(ppd_X[0][:, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 10, 191])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy for one-hot representation\n",
    "https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/4\n",
    "\n",
    "one-hotのままでなくて、Rでいうところのfactorに戻したほうがよさそう（？）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "input has to be a Tensor of size either (minibatch, C)(minibatch,C) or (minibatch, C, d_1, d_2, ..., d_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crossentropyの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplest example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2445,  0.3658,  0.9690, -0.6129,  0.8116],\n",
       "        [ 0.9633, -1.2911,  0.8367,  0.7545,  0.2851],\n",
       "        [-1.2417, -1.6772,  0.5704, -0.2913,  0.1365]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = criterion(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まとめて評価する場合（ただし、maskの適用方法がopen problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(y_tmp.permute(1 , 2,0 ) , batch_y.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(y_tmp.transpose(0 , 1).transpose(1,2) , batch_y.transpose(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/elm200/items/46633430c456dd90f1e3\n",
    "def try_gpu(e):\n",
    "    if torch.cuda.is_available():\n",
    "        return e.cuda()\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_use_gpu:\n",
    "    model = try_gpu(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ppd_X[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = range( 0 ,sample_size ,  batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_when_random = 1 / len(note_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epoch : 0   loss : 5.170687733396621   correct prob : 0.005680660695424892 correct / random : 1.0850061928261543'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'epoch : 1   loss : 5.169755488322681   correct prob : 0.0056859589326189695 correct / random : 1.0860181561302231'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'epoch : 2   loss : 5.169296458059618   correct prob : 0.005688569558975988 correct / random : 1.0865167857644136'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'epoch : 3   loss : 5.168613960677742   correct prob : 0.0056924533179835285 correct / random : 1.0872585837348538'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'epoch : 4   loss : 5.168107163424601   correct prob : 0.00569533896884692 correct / random : 1.0878097430497615'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'epoch : 5   loss : 5.167868801257094   correct prob : 0.005696696683995756 correct / random : 1.0880690666431894'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-fd040d658aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mbatch_y_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(n_epochs):\n",
    "    batch_loss = 0\n",
    "    shuffled_idx = torch.randperm(sample_size)\n",
    "    for i in batch_indices:\n",
    "        #display(\".\")\n",
    "        batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]\n",
    "\n",
    "        batch_X = ppd_X[0][: , batch_samples]\n",
    "        batch_y = ppd_y[0][:,  batch_samples]        \n",
    "        batch_mask = mask[batch_samples]\n",
    "        \n",
    "        if is_use_gpu:\n",
    "            batch_X = try_gpu(batch_X)\n",
    "            batch_y = try_gpu(batch_y)\n",
    "\n",
    "            batch_mask = try_gpu(batch_mask)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch_y_model = model(batch_X)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for j in range(batch_y.shape[1]):\n",
    "            loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    batch_loss /= torch.sum(mask).item()\n",
    "    losses.append(batch_loss)\n",
    "    mean_correct_prob = np.exp(-batch_loss)\n",
    "    \n",
    "    if k % 10 == 0:\n",
    "        display(\"epoch : {}   loss : {}   correct prob : {} correct / random : {}\".format(k , batch_loss ,\n",
    "                                                                        mean_correct_prob ,\n",
    "                                                                        mean_correct_prob / prob_when_random))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/jyori112/items/aad5703c1537c0139edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict() , 'saved/model20191022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = 0\n",
    "for i in batch_indices:\n",
    "    #display(\".\")\n",
    "    batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]\n",
    "\n",
    "    batch_X = ppd_X[0][: , batch_samples]\n",
    "    batch_y = ppd_y[0][:,  batch_samples]\n",
    "\n",
    "    batch_mask = mask[batch_samples]\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    batch_y_model = model(batch_X)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for j in range(batch_y.shape[1]):\n",
    "        loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])\n",
    "    batch_loss += loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    display(batch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one batch toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = batch_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = ppd_X[0][: , batch_samples]\n",
    "batch_y = ppd_y[0][:,  batch_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mask = mask[batch_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_model = model(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "\n",
    "for j in range(batch_y.shape[1]):\n",
    "    loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_model[0:batch_mask[j] , j ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y[0:batch_mask[j] , j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(y_tmp.permute(1 , 2,0 )[j , :, 0 : batch_mask[j]] , batch_y.transpose(0,1)[ j , 0 : batch_mask[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my own try and error　（この節のプロセスは必要ない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://d.hatena.ne.jp/naraba/20121201/p1\n",
    "#http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html\n",
    "\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set('musicxmlPath' , r\"C:\\Program Files (x86)\\Finale NotePad 2012\\Finale NotePad.exe\")\n",
    "#configure.run()\n",
    "#environment.keys()\n",
    "#environment.get('musicxmlPath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = corpus.parse('bach/bwv65.2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.analyze('key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[type(x) for x in s.getElementsByClass(stream.Stream)] #a lot of \"Part\"s\n",
    "[[print(type(y)) for y in x.getElementsByClass(stream.Stream)] for x in s.getElementsByClass(stream.Stream)]\n",
    "[print(x) for x  in s.flat.getElementsByClass(note.Note)]#example of how to flatten the score\n",
    "#unlike the deepjazz example, each Parts consists of \"Measure\"s\n",
    "type(s)#score\n",
    "\n",
    "#scoreとPartとMeasureがstreamの基本的なsubclass\n",
    "#scoreがpartを複数含み、partはmeasureを複数持つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting the note...\n",
    "Useful tips for jupyter notebook:\n",
    "\n",
    "https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://d.hatena.ne.jp/naraba/20121201/p1\n",
    "#http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html\n",
    "\n",
    "from music21 import *\n",
    "#environment.set('musicxmlPath' , r\"C:\\Program Files (x86)\\Finale NotePad 2012\\Finale NotePad.exe\")\n",
    "#configure.run()\n",
    "#environment.keys()\n",
    "#environment.get('musicxmlPath')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "楽譜を表示するためのおまじない\n",
    "\n",
    "参考URL:https://groups.google.com/forum/#!topic/music21list/FmU6HeNm7AM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = environment.UserSettings() #不必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'\n",
    "us['musescoreDirectPNGPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install musescore in linux (apt-getでインストールするのがポイント）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all those who will struggle with displaying scores from music21 within Jupyter Notebook on Linux (e.g. Ubuntu), follow these steps:\n",
    "https://stackoverflow.com/questions/49939275/python-music21-library-create-png-from-stream/49945456#49945456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MuseScoreのバージョンが2から3にあがっていたので、初期設定のままではうごきませんでした。\n",
    "https://qiita.com/nofrmm/items/c3662555b145f6b42d92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set(\"musescoreDirectPNGPath\", \"/usr/bin/musescore\")\n",
    "#environment.set(\"musicxmlPath\", \"/snap/bin/musescore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore.mscore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore.mscore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext music21.ipython21　#不必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルな例からスタート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note\n",
    "### noteの追加\n",
    "\n",
    "insert works as expected if it is \"Note to Stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B-5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "位置を指定して挿入する場合はinsertを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B-4\"))\n",
    "st1.insert(1,note.Note(\"B-4\"))\n",
    "st1.insert(2,note.Note(\"B#3\"))\n",
    "st1.insert(3,note.Note(\"B#3\"))\n",
    "st1.insert(4 , note.Note(\"B3\"))\n",
    "st1.insert(4 , note.Note(\"B2\"))\n",
    "st1.insert(5 , note.Note(\"C4\"))\n",
    "st1.insert(9 , note.Note(\"C4\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appendは最後に追加してくれるので位置の指定をしなくてよくて便利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.append(note.Note(\"C4\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音のシフト\n",
    "C4をMajor 3rd(長三度)だけシフトした音すなわちE4を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0 , note.Note(\"C4\"))\n",
    "st1.insert(6 , note.Note(\"C4\").transpose(\"M3\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E4をdouble diminished 6th（重減６度？）だけシフトした音を追加。\n",
    "ただし、double diminishedやdouble augumentedが実際に使われることはまれとのこと。\n",
    "（https://en.wikipedia.org/wiki/Interval_(music)#Main_intervals\n",
    "を参照。日本語版wikipediaはいまいちなので英語版を見ること）\n",
    "\n",
    "\n",
    "\n",
    "その他の参考URL：\n",
    "\n",
    "http://guitarchord-lab.com/theory/interval.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"E4\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"dd6\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、例えばC4の重減六度なるものは存在しないっぽい。したがって普通にラ（長６度・Major 6th）がappendされてしまう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"dd6\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして６度には完全６度というものは存在しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.append(note.Note(\"C4\").transpose(\"P6\")) #returns error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完全５度がなぜ完全ともみなされてきたか？それはドとソの周波数比がほぼほぼ2:3になっているから。\n",
    "すなわち、$2^{7/12}\\approx 1.5$であるから："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**(7/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に完全４度はほぼほぼ３：４になっている。すなわち、\n",
    "$2^{5/12}\\approx\\frac{4}{3}$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**(5/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（時間的な）offsetの範囲を調べるには以下のようにすればいいだろう（？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"E4\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"dd6\"))\n",
    "max_offset = max([x.offset for x in st1])\n",
    "print(max_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に付け加えるのをinsertでやるのであれば、以下のようにすればよいだろう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.insert(max_offset + 1 , note.Note(\"C3\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appendは以下のようにまとめて行うことができる（ただし、和音を付け加えるような動作ではない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.append([note.Note(\"D4\") , note.Note(\"E4\")])\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のように和音を追加することはできない・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.insert(max_offset + 1 , [note.Note(\"D4\") , note.Note(\"E4\")]) #returns error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あるoffsetの範囲を切り取るには・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.getElementsByOffset(0,4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、ヒエラルヒーがある場合の切り取り方はまだ試行削除中・・"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音の高さの差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 半音を100とするfloatで取出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval.notesToChromatic(note.Note(\"D5\") , note.Note(\"D#4\")).cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_diff = interval.notesToChromatic(note.Note(\"D4\") , note.Note(\"D4#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff.cents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.Note(\"C0\").transpose(1).nameWithOctave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音の大きさ（velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= note.Note(\"B-4\")\n",
    "n.volume.velocity = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テンポ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_score = stream.Score()\n",
    "bpm = 180\n",
    "run_score.insert(0.0, tempo.MetronomeMark(number=bpm)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音のoffset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "floatで指定されている場合とfraction.fractionで指定されている場合があるので統計処理する場合はfloat()でcastしてやる必要がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 楽器の指定、key signature（調記号・調号）の追加など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3=stream.Stream()\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(instrument.ElectricGuitar())\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(instrument.Piano())\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(key.KeySignature(1))\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(key.KeySignature(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記でいいのか？\n",
    "(慣習的にどうかはともかく入力として許容されるのか？)\n",
    "\n",
    "↑たぶんダメ。楽器はinsertで指定すべき！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3.getInstrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in st3.getInstruments()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 楽器名の文字列での取り出し方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3.getInstrument().instrumentName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score, part, measureについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scoreとPartとMeasureがstreamの基本的なsubclass\n",
    "\n",
    "scoreがpartを複数含み、partはmeasureを複数持つ、というのが基本的なScoreの構成（deep jazzの例のようにそうでないヒエラルヒーを持つ場合もある）。\n",
    "この「基本的な構成」を持つ例としてバッハの楽譜xmlファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bach = corpus.parse('bach/bwv65.2.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このscoreは４つのPartから構成される。\n",
    "\n",
    "各Partは各楽器に対応していて、それぞれひとつずつPartがある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(x) for x in s_bach.getElementsByClass(stream.Stream)] #a lot of \"Part\"s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このBachの例ではPartはmeasure(小節)から成る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\" \".join([str(type(y)) for y in x.getElementsByClass(stream.Stream)]) for x in s_bach.getElementsByClass(stream.Stream)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、\n",
    "\n",
    "http://web.mit.edu/music21/doc/usersGuide/usersGuide_06_stream2.html\n",
    "\n",
    "に注意があるように、PartはtimeSignatureやkeySignatureなども格納できるので、getElementByClassでアクセスするほうが安全:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([x for x in s_bach]))\n",
    "print(len([type(x) for x in s_bach.getElementsByClass(stream.Stream)] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### appendの動作\n",
    "noteを追加すると後ろに音を追加\n",
    "streamのsubclassを追加した場合はヒエラルヒーを構成する、けれど時間的順序はnoteを追加した場合と同じ？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.append(note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st0.append(st1)\n",
    "st0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.append(note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.append(st0)\n",
    "st2.append(st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.insert(0, note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.insert(0,note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.append(st0)\n",
    "st2.append(st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.insert(0, note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.insert(0,note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.insert(0 , st0)\n",
    "st2.insert(0, st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のヒエラルヒーと異なる構造を持つ例\n",
    "\n",
    "deepjazzの例では\n",
    "\n",
    "Score (midi_data) > Part (melody_stream) > Voice (melody1,2 , melody_voice) ＞ Note\n",
    "\n",
    "という階層に従ってデータを切り出しているように見える。\n",
    "すなわちPartはMeasureを持たず、その代わり（？）にVoice(声)を持っている："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz = converter.parse('C:/Users/t/PycharmProjects/deepjazz_in_a_file/midi/original_metheny.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_parts = [x for x in s_jazz.getElementsByClass(stream.Part)]\n",
    "len(s_jazz_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partは楽器が指定してあったりなかったり。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.getInstrument() for x in s_jazz.getElementsByClass(stream.Part)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices = [x for x in s_jazz_parts[0].getElementsByClass(stream.Voice)]\n",
    "len(s_jazz_part0_voices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partの構成要素であるvoiceにも同様にinstrumentが指定してあったりしなかったり。おそらく、partレベルで指定しておき、それが構成要素であるvoiceに遺伝している形か"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.getInstrument() for x in s_jazz_parts[a].getElementsByClass(stream.Voice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VoiceのなかにMeasureがあるかと思いきやそんなものはない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_jazz_part0_voices[0].getElementsByClass(stream.Measure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではなにが入っているかといえば、（ScoreのなかのPartのなかの）各PartのVoice[0]はおおむねChordから構成されている（他はnote.Rest, note.Noteが少々）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"   \".join([str(type(x)) for x in s_jazz_part0_voices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おそらく各パートのvoice[1]以降はおおむねnoteから構成されている（？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "であるが、deepjazzでchordパートを切り出す際にはそのように決め打つことなく、solo_stream[0]からremoveByClassでnoteを除外しつつすべてのchordを抽出している。\n",
    "また、melodyパートはsolo_stream[-1]から特に除外操作をすることなくすべてのnoteを抽出できている（？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"   \".join([str(type(x)) for x in s_jazz_part0_voices[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.mathgram.xyz/entry/plotly の下のほうを参考に（上の方は冗長）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get melody part, compress into single voice.\n",
    "melody_stream = s_jazz[5]     # For Metheny piece, Melody is Part #5.\n",
    "melody1, melody2 = melody_stream.getElementsByClass(stream.Voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly as offline mode\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "offline.init_notebook_mode(connected=False)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "columns = iris.feature_names\n",
    "\n",
    "# make dataframe\n",
    "df = pd.DataFrame(iris.data, columns=columns)\n",
    "\n",
    "# make trace\n",
    "trace = go.Scatter(\n",
    "    x = np.array([float(j.offset) for j in melody1][0:1000]),\n",
    "    y = np.array([float(j.offset) for j in melody2][0:1000]),\n",
    "    mode = \"markers\")\n",
    "\n",
    "# define layout\n",
    "layout = go.Layout(\n",
    "    showlegend=False)\n",
    "\n",
    "data = [trace]\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voice（声）とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q125207687\n",
    "参照。\n",
    "- 例えば合唱であれば、３声というのは三人で歌っているイメージ。\n",
    "- ピアノの場合、おなじことをひとりでできてしまうので単一のピアノパートのなかに複数のvoiceがありえる（ということか？）\n",
    "\n",
    "さらに推理すれば、\n",
    "\n",
    "- midiのなかのpartの分け方に恣意性はないが、そのなかのvoiceへの切り方には恣意性がある（切り分け方を変えても出てくる音は変わらない）ために、partのなかのvoiceはそもそもmergeすべき存在であると言えるか\n",
    "- メセニーの例でもパート５に存在するふたつのvoiceを「すべて」マージしてしまっている\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accompaniment  (伴奏) part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メセニーの例ではパート0,1,6,7が伴奏パートとのこと。\n",
    "- ではそれ以外は？？？\n",
    "- その他の多くのパートには楽器が登録されていない。\n",
    "- ただし、パート１１はパートゼロと同じくピアノがアサインされている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パート２はなにか意味があるような内容に見えるが・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz[2].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他方、パート１１はずっとソ＃をたたいているだけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz[11].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フラット化\n",
    "\n",
    "フラット化してもクラスは変わらない。すなわち、\n",
    "+ stream.Streamをフラットにするとフラットなstream.Streamが\n",
    "+ stream.Scoreをフラットにするとフラットなstream.Scoreが\n",
    "\n",
    "できることになる。\n",
    "\n",
    "そして、それぞれダイレクトにnoteが収納されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([str(type(x)) for x  in s_bach.flat.getElementsByClass(note.Note)])#example of how to flatten the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([str(type(x)) for x  in s_jazz.flat.getElementsByClass(note.Note)])#example of how to flatten the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(s_bach.flat))#score\n",
    "print(type(s_jazz.flat))#score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flat化およびvoice, partの使い分けについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flat化してひとつのvoiceに収納することが例えばdeep learningに突っ込むための合理的な前処理 \n",
    "- ただし、複数の楽器をまとめたオブジェクトの構成部品はpartでなくてはならない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chord（和音）について\n",
    "\n",
    "ChordもNoteもGeneralNoteの派生クラス\n",
    "\n",
    "参考URL：\n",
    "http://web.mit.edu/music21/doc/moduleReference/moduleNote.html#music21.note.GeneralNote\n",
    "\n",
    "deep jazzの解明のためにはChord、すなわち「和音」の理解が重要そうなので少し深堀してみる\n",
    "\n",
    "参考URL:\n",
    "http://web.mit.edu/music21/doc/usersGuide/usersGuide_07_chords.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chord（和音）の作り方："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor = chord.Chord([\"C4\", \"G4\",\"E-5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cMinor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pitch(音高)\n",
    "noteにはpitch（音高）があるが、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.Note(\"C4\").pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chord（和音）にはpitchはない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.pitch # returns errof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのかわりpitchesがある："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MajorかMinorか\n",
    "MajorかMinorかを判別してくれるメソッドはこれ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMajorTriad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英和対応：\n",
    "+ triad : 三和音\n",
    "+ major triad : 長三和音\n",
    "+ minor triad : 短三和音"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語wikipedia\n",
    "https://ja.wikipedia.org/wiki/%E7%9F%AD%E4%B8%89%E5%92%8C%E9%9F%B3\n",
    "によれば、短三和音は\n",
    "+ base\n",
    "+ base + m3\n",
    "+ base + P5\n",
    "によって構成される三和音とのことだが・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMinorTriad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "はTrueになるのでisMinorTriadの判定基準は日本語wikipediaの定義と異なる？\n",
    "\n",
    "というより、オクターブの違いは無視している(すわわちmod 12)ということか?\n",
    "\n",
    "より近接した音で構成される和音に変えるには以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.closedPosition().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コードの「名前」を知りたければ以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cMinor.commonName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メソッドisMajorTriadが何をやっているかは以下で解明できるはず：（だがスキップして先に進もう）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMajorTriad??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドミソをミソドにしたようなのを展開形という。展開形かどうかのチェックは以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.inversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale(音階)について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType = scale.MajorScale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://web.mit.edu/music21/doc/moduleReference/moduleScale.html\n",
    "\n",
    "によれば\n",
    "\n",
    "ConcreteScale.derive(other, comparisonAttribute='pitchClass')\n",
    "\n",
    "Return the closest-matching ConcreteScale based on the pitch collection provided as a Stream, a ConcreteScale, or a list of Pitch objects.\n",
    "\n",
    "要は音階がドミソ（すべて白鍵）ならドレミファソラシド（すべて白鍵）が含まれているC Major音階と推定するような感じか。\n",
    "推定アルゴリズムは変化の可能性ありと公式ウェブにも書いてある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType.derive(cMinor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = scale.MinorScale().derive(cMinor)\n",
    "scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定されたscaleに含まれる音を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([pitch for pitch in scales.getPitches()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドリアンスケールの場合の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType = scale.DorianScale()\n",
    "scales = scaleType.derive(cMinor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微分音（microtonal)\n",
    "\n",
    "参考URL:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Microtonal_music\n",
    "\n",
    "https://groups.google.com/forum/#!topic/music21list/-8PTr2gU8Hs\n",
    "\n",
    "http://web.mit.edu/music21/doc/moduleReference/modulePitch.html#music21.pitch.Pitch.convertMicrotonesToQuarterTones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他の基本的なscoreに対する操作(あまり必要ないかも)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.analyze('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tinynotationについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = converter.parse(\"tinynotation: 3/4 c4 d8 f g16 a g f#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = stream.Stream()\n",
    "s2.insert(0  , p)#adding part, first argument should be offset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=converter.parse(\"tinynotation: c4 d8 f g16 a g f#\")\n",
    "s2.insert(100,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=converter.parse(\"tinynotation: c4 d8 f g16 a g f#\")\n",
    "s2.insert(10,r)\n",
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.insert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?s2.insert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
