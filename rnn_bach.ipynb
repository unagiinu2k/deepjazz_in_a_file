{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%bash\n",
    "git commit -a -m \"studying basic stats further  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.rileynwong.com/blog/2019/2/25/generating-music-with-an-lstm-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(l, n):\n",
    "    \"\"\"\n",
    "    リストをサブリストに分割する\n",
    "    :param l: リスト\n",
    "    :param n: サブリストの要素数\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    for idx in range(0, len(l), n):\n",
    "        yield l[idx:idx + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import score2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score2df import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reload(score2df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 差分バージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_difference_based = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_discrete = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = str(is_difference_based) + \"_\"  + str(is_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = 'saved/df_scores_{}.pkl'.format(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_use_preprocessed_df = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame()\n",
    "if is_use_preprocessed_df:\n",
    "    df_scores = pd.read_pickle(pkl_path)\n",
    "else:\n",
    "    for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "        df_score = score2dataframe(file)\n",
    "        df_score = add_lags(df_score)\n",
    "        df_score = df_score.assign(file = file)\n",
    "        df_scores = df_scores.append(df_score , ignore_index = True )\n",
    "        \n",
    "    df_scores.to_pickle(pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239796, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>time</th>\n",
       "      <th>cent</th>\n",
       "      <th>n</th>\n",
       "      <th>dcent</th>\n",
       "      <th>dcent_lag1</th>\n",
       "      <th>dcent_lag2</th>\n",
       "      <th>dcent_lag3</th>\n",
       "      <th>dtime</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chorales/midi/028100b_.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chorales/midi/028100b_.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chorales/midi/028100b_.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F4</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chorales/midi/028100b_.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F3</td>\n",
       "      <td>4</td>\n",
       "      <td>-700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>chorales/midi/028100b_.mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pitch time    cent  n   dcent  dcent_lag1  dcent_lag2  dcent_lag3 dtime  \\\n",
       "0    F2    3 -1900.0  0     NaN         NaN         NaN         NaN   NaN   \n",
       "1    A3    3  -300.0  1     NaN         NaN         NaN         NaN   NaN   \n",
       "2    C4    3     0.0  2     NaN         NaN         NaN         NaN   NaN   \n",
       "3    F4    3   500.0  3     NaN         NaN         NaN         NaN   NaN   \n",
       "4    F3    4  -700.0  0  1200.0         NaN         NaN         NaN     1   \n",
       "\n",
       "                         file  \n",
       "0  chorales/midi/028100b_.mid  \n",
       "1  chorales/midi/028100b_.mid  \n",
       "2  chorales/midi/028100b_.mid  \n",
       "3  chorales/midi/028100b_.mid  \n",
       "4  chorales/midi/028100b_.mid  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage = df_scores.query('n == 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2count = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in set(df_scores.n):\n",
    "    n2count.append(df_scores.query('n == {}'.format(n)).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(pd.DataFrame({'n':list(set(df_scores.n)) , 'count': n2count}) , aes(x = 'n' , y = 'count'))  \\\n",
    " + geom_point() + scale_y_log10() + ggtitle('how many notes are simultaneously activated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores01 = df_scores.query('n in [0,1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores01 = df_scores01.assign(distance01 = df_scores.query('n in [0,1]').sort_values('n').groupby(['time' , 'file']).cent.diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores01.dropna(subset = ['distance01'] , inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scores01 , aes(x = 'distance01 / 100') ) + geom_histogram() + ggtitle('how far is it from the lowest to the second lowest?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_discrete:\n",
    "    dtype = str\n",
    "else:\n",
    "    dtype = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_set = set(df_stage.dcent.astype(dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(note_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_scores.dcent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_list = []\n",
    "for f in set(df_stage.file):\n",
    "    df_file = df_stage[df_stage.file == f]\n",
    "    \n",
    "    for n in set(df_file.n):\n",
    "        df_file_n = df_file[df_file.n == n]\n",
    "        \n",
    "        run_notes = df_file_n.dcent.astype(dtype)\n",
    "        for n in split_list(run_notes , max_sequence_length):\n",
    "            if len(n) > 10:\n",
    "                notes_list.append(n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notes_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.statsmodels.org/dev/example_formulas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = 'dcent ~ dcent_lag1' , data = df_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = 'dcent ~ dcent_lag1 + dcent_lag2' , data = df_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = 'dcent ~ dcent_lag1 + dcent_lag2 + dcent_lag3' , data = df_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?statsmodels.api.add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?mod.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.predict(df_stage.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparation I wrote  (note-basedの場合のhead. ただし、dcent baseのほうが良い可能性大.dcent-basedの場合はスキップ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not is_difference_based:\n",
    "    notes_list = []\n",
    "    note_set = set()\n",
    "    for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "        run_notes = []\n",
    "        print(file)\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = None\n",
    "        parts = instrument.partitionByInstrument(midi)\n",
    "        if parts: # file has instrument parts\n",
    "            #Pdb().set_trace()\n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                run_notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                #Pdb().set_trace()\n",
    "                run_notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        note_set = note_set | set(run_notes)\n",
    "        for n in split_list(run_notes , max_sequence_length):\n",
    "            if len(n) > 10:\n",
    "                notes_list.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-pack procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for continuous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_discrete:\n",
    "    raw_X = [torch.tensor(np.array(notes_list[i])[0:-1]).reshape([-1,1]) for i in range(len(notes_list))]\n",
    "    raw_y = [torch.tensor(np.array(notes_list[i])[1:]) for i in range(len(notes_list))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with label encoding (for discrete version)\n",
    "https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
    "に概ね準拠仕様と思ったが・・・\n",
    "\n",
    "- そもそもlabelencoder -> onehot  は今後必要ないよとwarning が出る\n",
    "- onehot の挙動が読みにくい\n",
    "\n",
    "のでlabelencodingしたあと直にnp.arrayをmanual onehote化したほうがいいのではないか？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_discrete:\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    le.fit(list(note_set))\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    labeled_notes_list = [le.transform(np.array(x)) for x in notes_list]\n",
    "\n",
    "    label_set = set(le.transform(list(note_set)))\n",
    "\n",
    "    raw_X = [torch.zeros(labeled_notes_list[i].shape[0] - 1 , len(label_set)) for i in range(len(notes_list))]\n",
    "\n",
    "    for i in range(len(notes_list)):\n",
    "        for j in range(labeled_notes_list[i].shape[0]-1):\n",
    "            raw_X[i][j , labeled_notes_list[i][j]] = 1.\n",
    "\n",
    "    raw_y = [torch.tensor(np.array(x[1:])) for x in labeled_notes_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad and pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_X = torch.nn.utils.rnn.pack_sequence(raw_X , enforce_sorted=False)\n",
    "\n",
    "ppd_X = torch.nn.utils.rnn.pad_packed_sequence(packed_X)\n",
    "\n",
    "packed_y = torch.nn.utils.rnn.pack_sequence(raw_y , enforce_sorted=False)\n",
    "\n",
    "ppd_y = torch.nn.utils.rnn.pad_packed_sequence(packed_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference\n",
    "\n",
    "- [OneHotEncoderだけでいける。LabelEncoderをかます必要なし]と当初思っていたがむしろ逆\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n",
    "\n",
    "Another possible good reference:\n",
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.Tensor([len(x) - 1 for x in notes_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ppd_X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM\n",
    "\n",
    "参考文献のpreprocessはあまり納得いかないので・・\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "をみつつやってみるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_size = len(ohe.get_feature_names())\n",
    "hidden_size = 50\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ppd_X[0].shape[2]\n",
    "hidden_size = ppd_X[0].shape[2]\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(my_model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
    "\n",
    "        #self.linear = nn.Linear(hidden_size, input_size) #output dimension has to be identical with the input dimension\n",
    "        #self.softmax = nn.functional.softmax()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        sequence_num = input.shape[1]\n",
    "        self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input, (self.h0, self.c0))\n",
    "        #y = self.linear(y)\n",
    "        y = nn.functional.softmax(y , dim = 2)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献に似せたモデル\n",
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "に似せたモデル\n",
    "現状ランダムの1.8倍程度の正答率にしかならないと思っていたがsoftmaxを二重にかけていた問題を解決したら劇的にパフォーマンスが向上した"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ppd_X[0].shape[2]\n",
    "hidden_size = 256 \n",
    "num_layers = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers , dropout):\n",
    "        #super(my_model, self).__init__()\n",
    "        \n",
    "        super().__init__()\n",
    "        #self.input_size = input_size\n",
    "        #self.hidden_size = hidden_size\n",
    "        #self.num_layers = num_layers\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers , dropout=dropout)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, input_size) #output dimension has to be identical with the input dimension\n",
    "        \n",
    "        \n",
    "        #self.sm = nn.Softmax(dim = 2)\n",
    "      \n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        #self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        #self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input)#, (self.h0, self.c0))\n",
    "        y = self.linear(y)\n",
    "        y = self.relu1(y)\n",
    "        #y = nn.functional.softmax(y , dim = 2)\n",
    "        #y = self.sm(y)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers , dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp = model.forward(ppd_X[0][:, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    連続バージョン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/49040180/change-tanh-activation-in-lstm-to-relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        \"\"\"\"Constructor of the class\"\"\"\n",
    "        super(LSTMCell, self).__init__()\n",
    "\n",
    "        self.nlayers = nlayers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        ih, hh = [], []\n",
    "        for i in range(nlayers):\n",
    "            ih.append(nn.Linear(input_size, 4 * hidden_size))\n",
    "            hh.append(nn.Linear(hidden_size, 4 * hidden_size))\n",
    "        self.w_ih = nn.ModuleList(ih)\n",
    "        self.w_hh = nn.ModuleList(hh)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"\"Defines the forward computation of the LSTMCell\"\"\"\n",
    "        hy, cy = [], []\n",
    "        for i in range(self.nlayers):\n",
    "            hx, cx = hidden[0][i], hidden[1][i]\n",
    "            gates = self.w_ih[i](input) + self.w_hh[i](hx)\n",
    "            i_gate, f_gate, c_gate, o_gate = gates.chunk(4, 1)\n",
    "\n",
    "            i_gate = F.sigmoid(i_gate)\n",
    "            f_gate = F.sigmoid(f_gate)\n",
    "            c_gate = F.tanh(c_gate)\n",
    "            o_gate = F.sigmoid(o_gate)\n",
    "\n",
    "            ncx = (f_gate * cx) + (i_gate * c_gate)\n",
    "            nhx = o_gate * F.tanh(ncx)\n",
    "            cy.append(ncx)\n",
    "            hy.append(nhx)\n",
    "            input = self.dropout(nhx)\n",
    "\n",
    "        hy, cy = torch.stack(hy, 0), torch.stack(cy, 0)\n",
    "        return hy, cy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# criterion (cross entropy lossはlog softmaxを含んでいるので二重に作用させないよう注意が必要）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy for one-hot representation\n",
    "https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/4\n",
    "\n",
    "one-hotのままでなくて、Rでいうところのfactorに戻したほうがよさそう（？）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "input has to be a Tensor of size either (minibatch, C)(minibatch,C) or (minibatch, C, d_1, d_2, ..., d_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_use_gpu = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and is_use_gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obsolete\n",
    "#https://qiita.com/elm200/items/46633430c456dd90f1e3\n",
    "\n",
    "def try_gpu(e):\n",
    "    if torch.cuda.is_available():\n",
    "        return e.cuda()\n",
    "    return e\n",
    "\n",
    "if is_use_gpu:\n",
    "    model = try_gpu(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ppd_X[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = range( 0 ,sample_size ,  batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_when_random = 1 / len(note_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(n_epochs):\n",
    "    batch_loss = 0\n",
    "    shuffled_idx = torch.randperm(sample_size)\n",
    "    for i in batch_indices:\n",
    "        #display(\".\")\n",
    "        batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]\n",
    "\n",
    "        batch_X = ppd_X[0][: , batch_samples]\n",
    "        batch_y = ppd_y[0][:,  batch_samples]        \n",
    "        batch_mask = mask[batch_samples]\n",
    "        \n",
    "        #if is_use_gpu:\n",
    "        #    batch_X = try_gpu(batch_X)\n",
    "        #    batch_y = try_gpu(batch_y)\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        batch_msk = batch_mask.to(device)# = try_gpu(batch_mask)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch_y_model = model(batch_X)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for j in range(batch_y.shape[1]):\n",
    "            loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    batch_loss /= torch.sum(mask).item()\n",
    "    losses.append(batch_loss)\n",
    "    mean_correct_prob = np.exp(-batch_loss)\n",
    "    \n",
    "    if k % 10 == 0:\n",
    "        display(\"epoch : {}   loss : {}   correct prob : {} correct / random : {}\".format(k , batch_loss ,\n",
    "                                                                        mean_correct_prob ,\n",
    "                                                                        mean_correct_prob / prob_when_random))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check errors using plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(pd.DataFrame({'n':range(len(losses)) , 'loss':losses}) , aes(x = 'n' , y ='loss')) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predicted vs realized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_idx = model(ppd_X[0].to(device)).detach().cpu().numpy().argmax(axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [[float(le.classes_[x]) for x in y_pred_idx[0:mask.numpy()[i] , i]] for i in range(y_pred_idx.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_realized = [[float(le.classes_[x]) for x in ppd_y[0].cpu().numpy()[0:mask.numpy()[i] , i]] for i in range(y_pred_idx.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter = pd.DataFrame({'pred':chain.from_iterable(y_pred) , 'realized':chain.from_iterable(y_realized)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scatter , aes(x = 'pred', y = 'realized')) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/jyori112/items/aad5703c1537c0139edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved/model20191027_{}'.format(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved/model20191103_{}'.format(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved/model20191110_{}'.format(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict() , model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers , dropout)\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = np.zeros(input_size , dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen[0] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = x_gen.reshape([1,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = torch.tensor(x_gen).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_gen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_gen):    \n",
    "    x1 = model.forward(x_gen)\n",
    "    x_gen = torch.cat([x_gen, x1[-1:]] , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternative generation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一番後ろだけアップデートするのでなく、まるごと（最初以外）置き換える手法も試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = np.zeros(input_size , dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen[0] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = x_gen.reshape([1,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = torch.tensor(x_gen).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_gen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_gen):    \n",
    "    x1 = model.forward(x_gen)\n",
    "    x_gen = torch.cat([x_gen[:1] , x1] , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen2 = x_gen.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xidx_gen = x_gen2.argmax(axis = 2).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xidx_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_gen= np.array( [float(le.classes_[xidx_gen[i]]) for i in range(xidx_gen.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_cumsum_gen = shift_gen.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.5\n",
    "base_note = note.Note(\"C5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(shift_cumsum_gen.shape[0]):\n",
    "    run_shift = int(shift_cumsum_gen[i] / 100)\n",
    "    if run_shift == 0:\n",
    "        run_note = base_note\n",
    "    else:                                      \n",
    "        run_note = base_note.transpose(interval.ChromaticInterval(run_shift))\n",
    "    st1.insert(0.5 * i , run_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=st1.write('lily.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.write('midi', fp ='tmp/rnn_generated.midi' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## playing sound (fail)\n",
    "\n",
    "jupyter lab上でのmidiファイル再生はいまのところできていない。一度ファイルに落として、jupyter notebook(labではなく）でplay_sound.ipynbで確認するのが現段階での最善手\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "freq = 44100    # audio CD quality\n",
    "bitsize = -16   # unsigned 16 bit\n",
    "channels = 2    # 1 is mono, 2 is stereo\n",
    "buffer = 1024    # number of samples\n",
    "pygame.mixer.init(freq, bitsize, channels, buffer)\n",
    "pygame.mixer.music.set_volume(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = midi.realtime.StreamPlayer(st1)\n",
    "sp.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 比較用にlinear modelを用いてgenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_gen = [800,200,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_gen = 100\n",
    "\n",
    "noise_strength = 0.1 #1にするとmseの誤差項の大きさをそのまま使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_gen):\n",
    "    df_gen = pd.DataFrame({'dcent_lag1':[sequence_gen[-1]] , 'dcent_lag2':[sequence_gen[-2]] , 'dcent_lag3':[sequence_gen[-3]]})\n",
    "    sequence_gen.append(int(res.predict(df_gen + noise_strength * np.sqrt(res.mse_resid) * np.random.normal()) / 100) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence_gen[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_cumsum_gen = np.array(sequence_gen).cumsum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.5\n",
    "base_note = note.Note(\"C5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(shift_cumsum_gen.shape[0]):\n",
    "    run_shift = int(shift_cumsum_gen[i] / 100)\n",
    "    if run_shift == 0:\n",
    "        run_note = base_note\n",
    "    else:                                      \n",
    "        run_note = base_note.transpose(interval.ChromaticInterval(run_shift))\n",
    "    st1.insert(0.5 * i , run_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shift == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=st1.write('lily.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.write('midi', fp ='tmp/tmp.midi' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = note.Note(\"D5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.transpose(interval.GenericInterval(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp = model.forward(ppd_X[0][:, 0:10].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ",rex0 = np.zeros(input_size , dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0[0] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x0.reshape([1,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.tensor(x0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = model.forward(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat([x0, x1] , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[-2:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat([x, x2[-2:-1]] , dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my own try and error　（この節のプロセスは必要ない）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting the note...\n",
    "Useful tips for jupyter notebook:\n",
    "\n",
    "https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://d.hatena.ne.jp/naraba/20121201/p1\n",
    "#http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html\n",
    "\n",
    "from music21 import *\n",
    "#environment.set('musicxmlPath' , r\"C:\\Program Files (x86)\\Finale NotePad 2012\\Finale NotePad.exe\")\n",
    "#configure.run()\n",
    "#environment.keys()\n",
    "#environment.get('musicxmlPath')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "楽譜を表示するためのおまじない\n",
    "\n",
    "参考URL:https://groups.google.com/forum/#!topic/music21list/FmU6HeNm7AM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = environment.UserSettings() #不必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'\n",
    "us['musescoreDirectPNGPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install musescore in linux (apt-getでインストールするのがポイント）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all those who will struggle with displaying scores from music21 within Jupyter Notebook on Linux (e.g. Ubuntu), follow these steps:\n",
    "https://stackoverflow.com/questions/49939275/python-music21-library-create-png-from-stream/49945456#49945456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MuseScoreのバージョンが2から3にあがっていたので、初期設定のままではうごきませんでした。\n",
    "https://qiita.com/nofrmm/items/c3662555b145f6b42d92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set(\"musescoreDirectPNGPath\", \"/usr/bin/musescore\")\n",
    "#environment.set(\"musicxmlPath\", \"/snap/bin/musescore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore.mscore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore.mscore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext music21.ipython21　#不必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルな例からスタート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note\n",
    "### noteの追加\n",
    "\n",
    "insert works as expected if it is \"Note to Stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B-5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "位置を指定して挿入する場合はinsertを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B-4\"))\n",
    "st1.insert(1,note.Note(\"B-4\"))\n",
    "st1.insert(2,note.Note(\"B#3\"))\n",
    "st1.insert(3,note.Note(\"B#3\"))\n",
    "st1.insert(4 , note.Note(\"B3\"))\n",
    "st1.insert(4 , note.Note(\"B2\"))\n",
    "st1.insert(5 , note.Note(\"C4\"))\n",
    "st1.insert(9 , note.Note(\"C4\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appendは最後に追加してくれるので位置の指定をしなくてよくて便利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.append(note.Note(\"C4\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音のシフト\n",
    "C4をMajor 3rd(長三度)だけシフトした音すなわちE4を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0 , note.Note(\"C4\"))\n",
    "st1.insert(6 , note.Note(\"C4\").transpose(\"M3\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E4をdouble diminished 6th（重減６度？）だけシフトした音を追加。\n",
    "ただし、double diminishedやdouble augumentedが実際に使われることはまれとのこと。\n",
    "（https://en.wikipedia.org/wiki/Interval_(music)#Main_intervals\n",
    "を参照。日本語版wikipediaはいまいちなので英語版を見ること）\n",
    "\n",
    "\n",
    "\n",
    "その他の参考URL：\n",
    "\n",
    "http://guitarchord-lab.com/theory/interval.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"E4\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"dd6\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、例えばC4の重減六度なるものは存在しないっぽい。したがって普通にラ（長６度・Major 6th）がappendされてしまう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"dd6\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして６度には完全６度というものは存在しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.append(note.Note(\"C4\").transpose(\"P6\")) #returns error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完全５度がなぜ完全ともみなされてきたか？それはドとソの周波数比がほぼほぼ2:3になっているから。\n",
    "すなわち、$2^{7/12}\\approx 1.5$であるから："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**(7/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に完全４度はほぼほぼ３：４になっている。すなわち、\n",
    "$2^{5/12}\\approx\\frac{4}{3}$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**(5/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（時間的な）offsetの範囲を調べるには以下のようにすればいいだろう（？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"E4\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"dd6\"))\n",
    "max_offset = max([x.offset for x in st1])\n",
    "print(max_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に付け加えるのをinsertでやるのであれば、以下のようにすればよいだろう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.insert(max_offset + 1 , note.Note(\"C3\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appendは以下のようにまとめて行うことができる（ただし、和音を付け加えるような動作ではない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.append([note.Note(\"D4\") , note.Note(\"E4\")])\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のように和音を追加することはできない・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.insert(max_offset + 1 , [note.Note(\"D4\") , note.Note(\"E4\")]) #returns error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あるoffsetの範囲を切り取るには・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.getElementsByOffset(0,4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、ヒエラルヒーがある場合の切り取り方はまだ試行削除中・・"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音の高さの差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 半音を100とするfloatで取出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval.notesToChromatic(note.Note(\"D5\") , note.Note(\"D#4\")).cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_diff = interval.notesToChromatic(note.Note(\"D4\") , note.Note(\"D4#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff.cents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.Note(\"C0\").transpose(1).nameWithOctave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音の大きさ（velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= note.Note(\"B-4\")\n",
    "n.volume.velocity = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テンポ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_score = stream.Score()\n",
    "bpm = 180\n",
    "run_score.insert(0.0, tempo.MetronomeMark(number=bpm)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音のoffset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "floatで指定されている場合とfraction.fractionで指定されている場合があるので統計処理する場合はfloat()でcastしてやる必要がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 楽器の指定、key signature（調記号・調号）の追加など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3=stream.Stream()\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(instrument.ElectricGuitar())\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(instrument.Piano())\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(key.KeySignature(1))\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(key.KeySignature(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記でいいのか？\n",
    "(慣習的にどうかはともかく入力として許容されるのか？)\n",
    "\n",
    "↑たぶんダメ。楽器はinsertで指定すべき！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3.getInstrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in st3.getInstruments()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 楽器名の文字列での取り出し方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3.getInstrument().instrumentName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score, part, measureについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scoreとPartとMeasureがstreamの基本的なsubclass\n",
    "\n",
    "scoreがpartを複数含み、partはmeasureを複数持つ、というのが基本的なScoreの構成（deep jazzの例のようにそうでないヒエラルヒーを持つ場合もある）。\n",
    "この「基本的な構成」を持つ例としてバッハの楽譜xmlファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bach = corpus.parse('bach/bwv65.2.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このscoreは４つのPartから構成される。\n",
    "\n",
    "各Partは各楽器に対応していて、それぞれひとつずつPartがある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(x) for x in s_bach.getElementsByClass(stream.Stream)] #a lot of \"Part\"s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このBachの例ではPartはmeasure(小節)から成る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\" \".join([str(type(y)) for y in x.getElementsByClass(stream.Stream)]) for x in s_bach.getElementsByClass(stream.Stream)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、\n",
    "\n",
    "http://web.mit.edu/music21/doc/usersGuide/usersGuide_06_stream2.html\n",
    "\n",
    "に注意があるように、PartはtimeSignatureやkeySignatureなども格納できるので、getElementByClassでアクセスするほうが安全:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([x for x in s_bach]))\n",
    "print(len([type(x) for x in s_bach.getElementsByClass(stream.Stream)] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### appendの動作\n",
    "noteを追加すると後ろに音を追加\n",
    "streamのsubclassを追加した場合はヒエラルヒーを構成する、けれど時間的順序はnoteを追加した場合と同じ？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.append(note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st0.append(st1)\n",
    "st0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.append(note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.append(st0)\n",
    "st2.append(st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.insert(0, note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.insert(0,note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.append(st0)\n",
    "st2.append(st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.insert(0, note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.insert(0,note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.insert(0 , st0)\n",
    "st2.insert(0, st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のヒエラルヒーと異なる構造を持つ例\n",
    "\n",
    "deepjazzの例では\n",
    "\n",
    "Score (midi_data) > Part (melody_stream) > Voice (melody1,2 , melody_voice) ＞ Note\n",
    "\n",
    "という階層に従ってデータを切り出しているように見える。\n",
    "すなわちPartはMeasureを持たず、その代わり（？）にVoice(声)を持っている："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz = converter.parse('C:/Users/t/PycharmProjects/deepjazz_in_a_file/midi/original_metheny.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_parts = [x for x in s_jazz.getElementsByClass(stream.Part)]\n",
    "len(s_jazz_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partは楽器が指定してあったりなかったり。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.getInstrument() for x in s_jazz.getElementsByClass(stream.Part)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices = [x for x in s_jazz_parts[0].getElementsByClass(stream.Voice)]\n",
    "len(s_jazz_part0_voices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partの構成要素であるvoiceにも同様にinstrumentが指定してあったりしなかったり。おそらく、partレベルで指定しておき、それが構成要素であるvoiceに遺伝している形か"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.getInstrument() for x in s_jazz_parts[a].getElementsByClass(stream.Voice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VoiceのなかにMeasureがあるかと思いきやそんなものはない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_jazz_part0_voices[0].getElementsByClass(stream.Measure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではなにが入っているかといえば、（ScoreのなかのPartのなかの）各PartのVoice[0]はおおむねChordから構成されている（他はnote.Rest, note.Noteが少々）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"   \".join([str(type(x)) for x in s_jazz_part0_voices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おそらく各パートのvoice[1]以降はおおむねnoteから構成されている（？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "であるが、deepjazzでchordパートを切り出す際にはそのように決め打つことなく、solo_stream[0]からremoveByClassでnoteを除外しつつすべてのchordを抽出している。\n",
    "また、melodyパートはsolo_stream[-1]から特に除外操作をすることなくすべてのnoteを抽出できている（？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"   \".join([str(type(x)) for x in s_jazz_part0_voices[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.mathgram.xyz/entry/plotly の下のほうを参考に（上の方は冗長）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get melody part, compress into single voice.\n",
    "melody_stream = s_jazz[5]     # For Metheny piece, Melody is Part #5.\n",
    "melody1, melody2 = melody_stream.getElementsByClass(stream.Voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly as offline mode\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "offline.init_notebook_mode(connected=False)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "columns = iris.feature_names\n",
    "\n",
    "# make dataframe\n",
    "df = pd.DataFrame(iris.data, columns=columns)\n",
    "\n",
    "# make trace\n",
    "trace = go.Scatter(\n",
    "    x = np.array([float(j.offset) for j in melody1][0:1000]),\n",
    "    y = np.array([float(j.offset) for j in melody2][0:1000]),\n",
    "    mode = \"markers\")\n",
    "\n",
    "# define layout\n",
    "layout = go.Layout(\n",
    "    showlegend=False)\n",
    "\n",
    "data = [trace]\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voice（声）とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q125207687\n",
    "参照。\n",
    "- 例えば合唱であれば、３声というのは三人で歌っているイメージ。\n",
    "- ピアノの場合、おなじことをひとりでできてしまうので単一のピアノパートのなかに複数のvoiceがありえる（ということか？）\n",
    "\n",
    "さらに推理すれば、\n",
    "\n",
    "- midiのなかのpartの分け方に恣意性はないが、そのなかのvoiceへの切り方には恣意性がある（切り分け方を変えても出てくる音は変わらない）ために、partのなかのvoiceはそもそもmergeすべき存在であると言えるか\n",
    "- メセニーの例でもパート５に存在するふたつのvoiceを「すべて」マージしてしまっている\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accompaniment  (伴奏) part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メセニーの例ではパート0,1,6,7が伴奏パートとのこと。\n",
    "- ではそれ以外は？？？\n",
    "- その他の多くのパートには楽器が登録されていない。\n",
    "- ただし、パート１１はパートゼロと同じくピアノがアサインされている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パート２はなにか意味があるような内容に見えるが・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz[2].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他方、パート１１はずっとソ＃をたたいているだけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz[11].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フラット化\n",
    "\n",
    "フラット化してもクラスは変わらない。すなわち、\n",
    "+ stream.Streamをフラットにするとフラットなstream.Streamが\n",
    "+ stream.Scoreをフラットにするとフラットなstream.Scoreが\n",
    "\n",
    "できることになる。\n",
    "\n",
    "そして、それぞれダイレクトにnoteが収納されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([str(type(x)) for x  in s_bach.flat.getElementsByClass(note.Note)])#example of how to flatten the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([str(type(x)) for x  in s_jazz.flat.getElementsByClass(note.Note)])#example of how to flatten the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(s_bach.flat))#score\n",
    "print(type(s_jazz.flat))#score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flat化およびvoice, partの使い分けについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flat化してひとつのvoiceに収納することが例えばdeep learningに突っ込むための合理的な前処理 \n",
    "- ただし、複数の楽器をまとめたオブジェクトの構成部品はpartでなくてはならない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chord（和音）について\n",
    "\n",
    "ChordもNoteもGeneralNoteの派生クラス\n",
    "\n",
    "参考URL：\n",
    "http://web.mit.edu/music21/doc/moduleReference/moduleNote.html#music21.note.GeneralNote\n",
    "\n",
    "deep jazzの解明のためにはChord、すなわち「和音」の理解が重要そうなので少し深堀してみる\n",
    "\n",
    "参考URL:\n",
    "http://web.mit.edu/music21/doc/usersGuide/usersGuide_07_chords.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chord（和音）の作り方："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor = chord.Chord([\"C4\", \"G4\",\"E-5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cMinor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pitch(音高)\n",
    "noteにはpitch（音高）があるが、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.Note(\"C4\").pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chord（和音）にはpitchはない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.pitch # returns errof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのかわりpitchesがある："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MajorかMinorか\n",
    "MajorかMinorかを判別してくれるメソッドはこれ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMajorTriad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英和対応：\n",
    "+ triad : 三和音\n",
    "+ major triad : 長三和音\n",
    "+ minor triad : 短三和音"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語wikipedia\n",
    "https://ja.wikipedia.org/wiki/%E7%9F%AD%E4%B8%89%E5%92%8C%E9%9F%B3\n",
    "によれば、短三和音は\n",
    "+ base\n",
    "+ base + m3\n",
    "+ base + P5\n",
    "によって構成される三和音とのことだが・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMinorTriad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "はTrueになるのでisMinorTriadの判定基準は日本語wikipediaの定義と異なる？\n",
    "\n",
    "というより、オクターブの違いは無視している(すわわちmod 12)ということか?\n",
    "\n",
    "より近接した音で構成される和音に変えるには以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.closedPosition().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コードの「名前」を知りたければ以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cMinor.commonName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メソッドisMajorTriadが何をやっているかは以下で解明できるはず：（だがスキップして先に進もう）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMajorTriad??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドミソをミソドにしたようなのを展開形という。展開形かどうかのチェックは以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.inversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale(音階)について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType = scale.MajorScale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://web.mit.edu/music21/doc/moduleReference/moduleScale.html\n",
    "\n",
    "によれば\n",
    "\n",
    "ConcreteScale.derive(other, comparisonAttribute='pitchClass')\n",
    "\n",
    "Return the closest-matching ConcreteScale based on the pitch collection provided as a Stream, a ConcreteScale, or a list of Pitch objects.\n",
    "\n",
    "要は音階がドミソ（すべて白鍵）ならドレミファソラシド（すべて白鍵）が含まれているC Major音階と推定するような感じか。\n",
    "推定アルゴリズムは変化の可能性ありと公式ウェブにも書いてある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType.derive(cMinor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = scale.MinorScale().derive(cMinor)\n",
    "scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定されたscaleに含まれる音を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([pitch for pitch in scales.getPitches()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドリアンスケールの場合の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType = scale.DorianScale()\n",
    "scales = scaleType.derive(cMinor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微分音（microtonal)\n",
    "\n",
    "参考URL:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Microtonal_music\n",
    "\n",
    "https://groups.google.com/forum/#!topic/music21list/-8PTr2gU8Hs\n",
    "\n",
    "http://web.mit.edu/music21/doc/moduleReference/modulePitch.html#music21.pitch.Pitch.convertMicrotonesToQuarterTones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他の基本的なscoreに対する操作(あまり必要ないかも)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.analyze('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tinynotationについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = converter.parse(\"tinynotation: 3/4 c4 d8 f g16 a g f#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = stream.Stream()\n",
    "s2.insert(0  , p)#adding part, first argument should be offset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=converter.parse(\"tinynotation: c4 d8 f g16 a g f#\")\n",
    "s2.insert(100,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=converter.parse(\"tinynotation: c4 d8 f g16 a g f#\")\n",
    "s2.insert(10,r)\n",
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.insert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?s2.insert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
