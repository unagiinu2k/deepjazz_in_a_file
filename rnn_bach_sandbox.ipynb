{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git commit -a -m \"checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.rileynwong.com/blog/2019/2/25/generating-music-with-an-lstm-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to show score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/cuthbertLab/music21/issues/260　の方法で見えるようになった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set(\"musescoreDirectPNGPath\", \"/usr/bin/musescore\")\n",
    "environment.set(\"graphicsPath\", \"/usr/bin/lilypond\")\n",
    "environment.set('lilypondPath', '/usr/bin/lilypond' )\n",
    "environment.set(\"musicxmlPath\", \"/usr/bin/musescore\")\n",
    "environment.set('midiPath' , '/usr/bin/timidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B-5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename=st1.write('lily.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = converter.parse('tinyNotation: 4/4 e8 e8 r e8 r c8 e8 r g4 r G4 r')\n",
    "Image(filename=s.write('lily.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no show\n",
    "st1.show('musicxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to play midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp/tmp.midi'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.write('midi', fp ='tmp/tmp.midi' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/midi;base64,TVRoZAAAAAYAAQABBABNVHJrAAAAWAD/AwAA4ABAAP9YBAQCGAgAkEBahACAQAAAkEBahACAQACEAJBAWoQAgEAAhACQPFqEAIA8AACQQFqEAIBAAIQAkENaiACAQwCIAJA3WogAgDcAiAD/LwA=\" type=\"audio/midi\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Audio(filename = 'tmp/tmp.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/midi;base64,TVRoZAAAAAYAAQABBABNVHJrAAAAWAD/AwAA4ABAAP9YBAQCGAgAkEBahACAQAAAkEBahACAQACEAJBAWoQAgEAAhACQPFqEAIA8AACQQFqEAIBAAIQAkENaiACAQwCIAJA3WogAgDcAiAD/LwA=\" type=\"audio/midi\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Audio(filename=s.write('midi'), rate = 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://kquoe2.hatenablog.com/entry/2019/05/09/174605\n",
    "を見ながら試行錯誤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv1102'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv1102');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQABBABNVHJrAAAAWAD/AwAA4ABAAP9YBAQCGAgAkEBahACAQAAAkEBahACAQACEAJBAWoQAgEAAhACQPFqEAIA8AACQQFqEAIBAAIQAkENaiACAQwCIAJA3WogAgDcAiAD/LwA=');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下がjupyter labでもworkした！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/10983462/how-can-i-produce-real-time-audio-output-from-music-made-with-music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "freq = 44100    # audio CD quality\n",
    "bitsize = -16   # unsigned 16 bit\n",
    "channels = 2    # 1 is mono, 2 is stereo\n",
    "buffer = 1024    # number of samples\n",
    "pygame.mixer.init(freq, bitsize, channels, buffer)\n",
    "pygame.mixer.music.set_volume(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = midi.realtime.StreamPlayer(s)\n",
    "sp.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bokeh initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.transform import jitter\n",
    "import bokeh.plotting as bp\n",
    "from bokeh import palettes\n",
    "bp.output_notebook()\n",
    "from bokeh.models import ColumnDataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to deal with codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"midi/sonate_31.mid\"\n",
    "midi = converter.parse(file)\n",
    "notes_to_parse = None\n",
    "max_simultaneous = 4\n",
    "#pitches = [[] for i in range(max_simultaneous)]\n",
    "#times = [[] for i in range(max_simultaneous)]\n",
    "#diffs = [[] for i in range(max_simultaneous)]\n",
    "pitches = []\n",
    "times = []\n",
    "diffs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = instrument.partitionByInstrument(midi)\n",
    "if parts: # file has instrument parts\n",
    "    notes_to_parse = parts.parts[0].recurse()\n",
    "else: # file has notes in a flat structure\n",
    "    notes_to_parse = midi.flat.notes\n",
    "for element in notes_to_parse:\n",
    "\n",
    "    if isinstance(element, note.Note):        \n",
    "        #run_notes = [element]\n",
    "        pitches.append(str(element.pitch))\n",
    "        diffs.append(interval.notesToChromatic(note.Note(\"C4\") , element).cents)\n",
    "        times.append(element.offset)\n",
    "    elif isinstance(element, chord.Chord):           \n",
    "        run_chord = element\n",
    "        for i in range(min(len(element.normalOrder) , max_simultaneous)):\n",
    "            pitches.append(element.pitches[i])\n",
    "            diffs.append(interval.notesToChromatic(note.Note(\"C4\") , run_chord.notes[i]).cents)\n",
    "            times.append(element.offset)\n",
    "\n",
    "\n",
    "df_score = pd.DataFrame({'pitch' : pitches , 'time' : times , 'cent' : diffs })\n",
    "df_score.sort_values(['time' , 'cent'] , inplace=True)\n",
    "\n",
    "df_score = df_score.assign(n = df_score.groupby('time').cumcount())\n",
    "\n",
    "df_score = df_score.assign(dcent = df_score.groupby('n').cent.diff())\n",
    "return df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparation I wrote  (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(l, n):\n",
    "    \"\"\"\n",
    "    リストをサブリストに分割する\n",
    "    :param l: リスト\n",
    "    :param n: サブリストの要素数\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    for idx in range(0, len(l), n):\n",
    "        yield l[idx:idx + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notes_list = []\n",
    "note_set = set()\n",
    "for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "    run_notes = []\n",
    "    print(file)\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    if parts: # file has instrument parts\n",
    "        #Pdb().set_trace()\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            run_notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            Pdb().set_trace()\n",
    "            #Pdb().set_trace()\n",
    "            run_notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    note_set = note_set | set(run_notes)\n",
    "    for n in split_list(run_notes , max_sequence_length):\n",
    "        if len(n) > 10:\n",
    "            notes_list.append(n)\n",
    "    #notes_list.append(run_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to be ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as in tutorial on the web (to be skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "notes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "notes = []\n",
    "for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "    print(file)\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    if parts: # file has instrument parts\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example : when there is only one midi file (to be skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"midi/sonate_31.mid\"\n",
    "#file = 'chorales/midi/065900b_.mid'\n",
    "midi = converter.parse(file)\n",
    "notes_to_parse = None\n",
    "notes = []\n",
    "parts = instrument.partitionByInstrument(midi)\n",
    "if parts: # file has instrument parts\n",
    "    notes_to_parse = parts.parts[0].recurse()\n",
    "else: # file has notes in a flat structure\n",
    "    notes_to_parse = midi.flat.notes\n",
    "for element in notes_to_parse:\n",
    "    if isinstance(element, note.Note):\n",
    "        notes.append(str(element.pitch))\n",
    "    elif isinstance(element, chord.Chord):   \n",
    "        run_chord = element\n",
    "        notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.show('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flat notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_notes = [x for x in midi.flat.notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note = flat_notes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [x.offset for x in midi.flat.notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 頻度チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = pd.DataFrame({'x' : notes[0:-1] , 'y':notes[1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = run_df.assign(z = run_df.x + ' ' +  run_df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(run_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_range = list(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure(x_range = run_range , y_range = run_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.scatter(jitter('x' , width = 0.5 , range = p.x_range) , jitter('y' , width = 0.5 , range = p.y_range) , source = source )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 差分に基づくデータ記述の試み(20191022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数化済みバージョン\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score2df import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?score2df.score2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = score2df.score2df(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2df.add_lags(df_score).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = df_score.assign(dcent_lag1 = df_score.groupby('n').dcent.shift(1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dplyr::spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/mwmsnn/items/6a464865759231aa888d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベタ打ちバージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"midi/sonate_31.mid\"\n",
    "file = 'chorales/midi/065900b_.mid'\n",
    "midi = converter.parse(file)\n",
    "notes_to_parse = None\n",
    "max_simultaneous = 4\n",
    "#pitches = [[] for i in range(max_simultaneous)]\n",
    "#times = [[] for i in range(max_simultaneous)]\n",
    "#diffs = [[] for i in range(max_simultaneous)]\n",
    "pitches = []\n",
    "times = []\n",
    "diffs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = instrument.partitionByInstrument(midi)\n",
    "if parts: # file has instrument parts\n",
    "    notes_to_parse = parts.parts[0].recurse()\n",
    "else: # file has notes in a flat structure\n",
    "    notes_to_parse = midi.flat.notes\n",
    "for element in notes_to_parse:\n",
    "    \n",
    "    if isinstance(element, note.Note):        \n",
    "        #run_notes = [element]\n",
    "        pitches.append(str(element.pitch))\n",
    "        diffs.append(interval.notesToChromatic(note.Note(\"C4\") , element).cents)\n",
    "        times.append(element.offset)\n",
    "    elif isinstance(element, chord.Chord):           \n",
    "        run_chord = element\n",
    "        for i in range(min(len(element.normalOrder) , max_simultaneous)):\n",
    "            pitches.append(element.pitches[i])\n",
    "            diffs.append(interval.notesToChromatic(note.Note(\"C4\") , run_chord.notes[i]).cents)\n",
    "            times.append(element.offset)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame({'pitch' : pitches , 'time' : times , 'cent' : diffs })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.sort_values(['time' , 'cent'] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = df_score.assign(n = df_score.groupby('time').cumcount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df_score[df_score.n == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_score[df_score.n == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.assign(dcent = df0.cent.diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.assign(dcent_lag1 = df0.dcent.shift(1))\n",
    "df0 = df0.assign(dcent_lag2 = df0.dcent.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap , geom_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df0 , aes(x = 'dcent / 200')) + geom_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dcentの値域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df0['dcent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "たかだか７１とか（もともとのnoteの数より少ない？）なので離散化してもなんとかなりそう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dcentは自己相関がありそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df0 , aes(x = 'dcent / 200' , y = 'dcent_lag1 / 200')) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "\n",
    "https://www.statsmodels.org/dev/example_formulas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = 'dcent ~ dcent_lag1' , data = df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### momentumもありそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = 'dcent ~ dcent_lag1 + dcent_lag2' , data = df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.scatter(df0.cent , df0.dcent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.scatter('cent' , 'dcent' , source = source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_list = [x for x in notes_to_parse if isinstance(x , note.Note)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(note_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note = note_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(a_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding new flow (main)\n",
    "\n",
    "https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
    "に概ね準拠仕様と思ったが・・・\n",
    "\n",
    "- そもそもlabelencoder -> onehot  は今後必要ないよとwarning が出る\n",
    "- onehot の挙動が読みにくい\n",
    "\n",
    "のでlabelencodingしたあと直にnp.arrayをmanual onehote化したほうがいいのではないか？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(list(note_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_notes_list = [le.transform(np.array(x)) for x in notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set(le.transform(list(note_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = [torch.zeros(labeled_notes_list[i].shape[0] - 1 , len(label_set)) for i in range(len(notes_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(notes_list)):\n",
    "    for j in range(labeled_notes_list[i].shape[0]-1):\n",
    "        raw_X[i][j , labeled_notes_list[i][j]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_X = torch.nn.utils.rnn.pack_sequence(raw_X , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X = torch.nn.utils.rnn.pad_packed_sequence(packed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_y = [torch.tensor(np.array(x[1:])) for x in labeled_notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_y = torch.nn.utils.rnn.pack_sequence(raw_y , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_y = torch.nn.utils.rnn.pad_packed_sequence(packed_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding previous flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohnotes = ohe.fit_transform(np.array(notes).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohnotes = ohe.fit(np.array(list(note_set)).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohnotes_list = [ohe.transform(np.array(x).reshape(-1,1)) for x in notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ohnotes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = [torch.Tensor(x.toarray()) for x in ohnotes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_X = torch.nn.utils.rnn.pack_sequence(raw_X , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X = torch.nn.utils.rnn.pad_packed_sequence(packed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference\n",
    "\n",
    "- OneHotEncoderだけでいける。LabelEncoderをかます必要なしと当初思っていたがむしろ逆\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n",
    "\n",
    "Another possible good reference:\n",
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obsolete : label encoder: 不必要という判断になっていたが結局こちらのほうがいいかも？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(list(note_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inotes = le.transform(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inotes[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.Tensor([len(x) - 1 for x in notes_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ppd_X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM\n",
    "\n",
    "参考文献のpreprocessはあまり納得いかないので・・\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "をみつつやってみるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  復習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "sequence_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(sequence_length, sequence_num, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(num_layers , sequence_num , hidden_size)\n",
    "c0 = torch.randn(num_layers , sequence_num, hidden_size)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputの最後尾（sequence length方向の末尾）とhnは一致する:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 復習２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = ppd_X[0][: , 0:10 ]\n",
    "batch_y = ppd_y[0][:,  0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_num = batch_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(num_layers , sequence_num , hidden_size)\n",
    "c0 = torch.randn(num_layers , sequence_num, hidden_size)\n",
    "output, (hn, cn) = rnn(batch_X, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_size = len(ohe.get_feature_names())\n",
    "hidden_size = 50\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ppd_X[0].shape[2]\n",
    "hidden_size = ppd_X[0].shape[2]\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(my_model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
    "\n",
    "        #self.linear = nn.Linear(hidden_size, input_size) #output dimension has to be identical with the input dimension\n",
    "        #self.softmax = nn.functional.softmax()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        sequence_num = input.shape[1]\n",
    "        self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input, (self.h0, self.c0))\n",
    "        #y = self.linear(y)\n",
    "        y = nn.functional.softmax(y , dim = 2)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献に似せたモデル\n",
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "に似せたモデル\n",
    "現状ランダムの1.8倍程度の正答率にしかならない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ppd_X[0].shape[2]\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers , dropout):\n",
    "        #super(my_model, self).__init__()\n",
    "        \n",
    "        super().__init__()\n",
    "        #self.input_size = input_size\n",
    "        #self.hidden_size = hidden_size\n",
    "        #self.num_layers = num_layers\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers , dropout=dropout)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, input_size) #output dimension has to be identical with the input dimension\n",
    "      \n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        #self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        #self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input)#, (self.h0, self.c0))\n",
    "        y = self.linear(y)\n",
    "        y = self.relu1(y)\n",
    "        y = nn.functional.softmax(y , dim = 2)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers , dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp = model.forward(ppd_X[0][:, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy for one-hot representation\n",
    "https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/4\n",
    "\n",
    "one-hotのままでなくて、Rでいうところのfactorに戻したほうがよさそう（？）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "input has to be a Tensor of size either (minibatch, C)(minibatch,C) or (minibatch, C, d_1, d_2, ..., d_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crossentropyの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplest example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = criterion(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まとめて評価する場合（ただし、maskの適用方法がopen problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(y_tmp.permute(1 , 2,0 ) , batch_y.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(y_tmp.transpose(0 , 1).transpose(1,2) , batch_y.transpose(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/elm200/items/46633430c456dd90f1e3\n",
    "def try_gpu(e):\n",
    "    if torch.cuda.is_available():\n",
    "        return e.cuda()\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_use_gpu:\n",
    "    model = try_gpu(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ppd_X[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = range( 0 ,sample_size ,  batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_when_random = 1 / len(note_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(n_epochs):\n",
    "    batch_loss = 0\n",
    "    shuffled_idx = torch.randperm(sample_size)\n",
    "    for i in batch_indices:\n",
    "        #display(\".\")\n",
    "        batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]\n",
    "\n",
    "        batch_X = ppd_X[0][: , batch_samples]\n",
    "        batch_y = ppd_y[0][:,  batch_samples]        \n",
    "        batch_mask = mask[batch_samples]\n",
    "        \n",
    "        if is_use_gpu:\n",
    "            batch_X = try_gpu(batch_X)\n",
    "            batch_y = try_gpu(batch_y)\n",
    "\n",
    "            batch_mask = try_gpu(batch_mask)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch_y_model = model(batch_X)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for j in range(batch_y.shape[1]):\n",
    "            loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    batch_loss /= torch.sum(mask).item()\n",
    "    losses.append(batch_loss)\n",
    "    mean_correct_prob = np.exp(-batch_loss)\n",
    "    \n",
    "    \n",
    "    display(\"epoch : {}   loss : {}   correct prob : {} correct / random : {}\".format(k , batch_loss ,\n",
    "                                                                        mean_correct_prob ,\n",
    "                                                                        mean_correct_prob / prob_when_random))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/jyori112/items/aad5703c1537c0139edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict() , 'saved/model20191022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = 0\n",
    "for i in batch_indices:\n",
    "    #display(\".\")\n",
    "    batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]\n",
    "\n",
    "    batch_X = ppd_X[0][: , batch_samples]\n",
    "    batch_y = ppd_y[0][:,  batch_samples]\n",
    "\n",
    "    batch_mask = mask[batch_samples]\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    batch_y_model = model(batch_X)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for j in range(batch_y.shape[1]):\n",
    "        loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])\n",
    "    batch_loss += loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    display(batch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one batch toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = batch_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = ppd_X[0][: , batch_samples]\n",
    "batch_y = ppd_y[0][:,  batch_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mask = mask[batch_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_model = model(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "\n",
    "for j in range(batch_y.shape[1]):\n",
    "    loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_model[0:batch_mask[j] , j ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y[0:batch_mask[j] , j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(y_tmp.permute(1 , 2,0 )[j , :, 0 : batch_mask[j]] , batch_y.transpose(0,1)[ j , 0 : batch_mask[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my own try and error　（この節のプロセスは必要ない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://d.hatena.ne.jp/naraba/20121201/p1\n",
    "#http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html\n",
    "\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set('musicxmlPath' , r\"C:\\Program Files (x86)\\Finale NotePad 2012\\Finale NotePad.exe\")\n",
    "#configure.run()\n",
    "#environment.keys()\n",
    "#environment.get('musicxmlPath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = corpus.parse('bach/bwv65.2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.key.Key of a minor>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.analyze('key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv3399'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv3399');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQAEBABNVHJrAAABTgD/AwdTb3ByYW5vAOAAQADAAAD/WQIAAAD/WAQDAhgIAJBFWogAgEUAAJBFWpAAgEUAAJBFWogAgEUAAJBHWpAAgEcAAJBHWogAgEcAAJBIWogAgEgAAJBHWogAgEcAAJBFWogAgEUAAJBDWpgAgEMAAJBIWpAAgEgAAJBKWogAgEoAAJBIWpAAgEgAAJBHWogAgEcAAJBIWpAAgEgAAJBIWogAgEgAAJBIWpAAgEgAAJBIWogAgEgAAJBHWpAAgEcAAJBFWogAgEUAAJBFWogAgEUAAJBHWogAgEcAAJBEWogAgEQAAJBFWpAAgEUAAJBFWogAgEUAAJBDWpAAgEMAAJBFWogAgEUAAJBHWpAAgEcAAJBHWogAgEcAAJBIWpAAgEgAAJBHWogAgEcAAJBFWpAAgEUAAJBEWogAgEQAAJBFWpAAgEUAiAD/LwBNVHJrAAABSwD/AwRBbHRvAOAAQADAAAD/WQIAAAD/WAQDAhgIAJBAWogAgEAAAJBAWpAAgEAAAJBFWogAgEUAAJBDWpAAgEMAAJBDWogAgEMAAJBDWpAAgEMAAJBBWogAgEEAAJBAWpgAgEAAAJBDWpAAgEMAAJBEWogAgEQAAJBFWpAAgEUAAJBDWogAgEMAAJBDWpAAgEMAAJBDWogAgEMAAJBFWpAAgEUAAJBCWogAgEIAAJBDWpAAgEMAAJBDWpAAgEMAAJBCWogAgEIAAJBAWogAgEAAAJBAWpAAgEAAAJA+WogAgD4AAJA+WogAgD4AAJBAWogAgEAAAJA+WogAgD4AAJA+WpAAgD4AAJBBWogAgEEAAJBAWogAgEAAAJBBWogAgEEAAJBDWpAAgEMAAJBCWogAgEIAAJBAWogAgEAAAJBAWpAAgEAAiAD/LwBNVHJrAAABZwD/AwVUZW5vcgDgAEAAwAAA/1kCAAAA/1gEAwIYCACQPFqIAIA8AACQPFqQAIA8AACQPlqIAIA+AACQPlqQAIA+AACQPlqIAIA+AACQPFqIAIA8AACQQFqIAIBAAACQPFqIAIA8AACQPFqYAIA8AACQQFqgAIBAAACQPlqIAIA+AACQPlqIAIA+AACQQFqQAIBAAACQQFqIAIBAAACQQFqIAIBAAACQPlqIAIA+AACQPlqIAIA+AACQPlqIAIA+AACQQFqIAIBAAACQQFqIAIBAAACQPlqIAIA+AACQO1qIAIA7AACQO1qIAIA7AACQPFqQAIA8AACQOVqIAIA5AACQO1qIAIA7AACQPFqIAIA8AACQOVqIAIA5AACQN1qIAIA3AACQO1qIAIA7AACQPlqIAIA+AACQPFqIAIA8AACQPlqQAIA+AACQPFqQAIA8AACQO1qIAIA7AACQPVqQAIA9AIgA/y8ATVRyawAAAZwA/wMEQmFzcwDgAEAAwAAA/1kCAAAA/1gEAwIYCACQLVqIAIAtAACQOVqIAIA5AACQN1qIAIA3AACQNlqIAIA2AACQN1qIAIA3AACQMlqIAIAyAACQNVqIAIA1AACQNFqIAIA0AACQMFqIAIAwAACQNVqIAIA1AACQMFqYAIAwAACQMFqIAIAwAACQPFqIAIA8AACQO1qIAIA7AACQOVqIAIA5AACQNlqIAIA2AACQN1qIAIA3AACQMFqQAIAwAACQPFqIAIA8AACQOVqIAIA5AACQNlqIAIA2AACQMlqIAIAyAACQN1qIAIA3AACQNFqIAIA0AACQMVqIAIAxAACQMlqIAIAyAACQM1qIAIAzAACQNFqIAIA0AACQLVqQAIAtAACQNVqQAIA1AACQNFqIAIA0AACQNlqIAIA2AACQN1qIAIA3AACQNlqIAIA2AACQOFqIAIA4AACQOVqIAIA5AACQMlqIAIAyAACQNFqIAIA0AACQNVqIAIA1AACQM1qIAIAzAACQNFqIAIA0AACQLVqQAIAtAIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<class 'music21.stream.Measure'>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note F#>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note F>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note F>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note F>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note G#>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note F#>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note F#>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note F#>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C#>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note F#>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note D#>\n",
      "<music21.note.Note G#>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note F>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note F>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note F#>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note F#>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note F>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note G#>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note F>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note D>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note G>\n",
      "<music21.note.Note C>\n",
      "<music21.note.Note F>\n",
      "<music21.note.Note F#>\n",
      "<music21.note.Note D#>\n",
      "<music21.note.Note G#>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note B>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note A>\n",
      "<music21.note.Note E>\n",
      "<music21.note.Note C#>\n",
      "<music21.note.Note A>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "music21.stream.Score"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(x) for x in s.getElementsByClass(stream.Stream)] #a lot of \"Part\"s\n",
    "[[print(type(y)) for y in x.getElementsByClass(stream.Stream)] for x in s.getElementsByClass(stream.Stream)]\n",
    "[print(x) for x  in s.flat.getElementsByClass(note.Note)]#example of how to flatten the score\n",
    "#unlike the deepjazz example, each Parts consists of \"Measure\"s\n",
    "type(s)#score\n",
    "\n",
    "#scoreとPartとMeasureがstreamの基本的なsubclass\n",
    "#scoreがpartを複数含み、partはmeasureを複数持つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting the note...\n",
    "Useful tips for jupyter notebook:\n",
    "\n",
    "https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://d.hatena.ne.jp/naraba/20121201/p1\n",
    "#http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html\n",
    "\n",
    "from music21 import *\n",
    "#environment.set('musicxmlPath' , r\"C:\\Program Files (x86)\\Finale NotePad 2012\\Finale NotePad.exe\")\n",
    "#configure.run()\n",
    "#environment.keys()\n",
    "#environment.get('musicxmlPath')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "楽譜を表示するためのおまじない\n",
    "\n",
    "参考URL:https://groups.google.com/forum/#!topic/music21list/FmU6HeNm7AM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = environment.UserSettings() #不必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'\n",
    "us['musescoreDirectPNGPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install musescore in linux (apt-getでインストールするのがポイント）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all those who will struggle with displaying scores from music21 within Jupyter Notebook on Linux (e.g. Ubuntu), follow these steps:\n",
    "https://stackoverflow.com/questions/49939275/python-music21-library-create-png-from-stream/49945456#49945456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MuseScoreのバージョンが2から3にあがっていたので、初期設定のままではうごきませんでした。\n",
    "https://qiita.com/nofrmm/items/c3662555b145f6b42d92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/usr/bin/musescore'\n",
    "us['musescoreDirectPNGPath'] = r'/usr/bin/musescore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set(\"musescoreDirectPNGPath\", \"/usr/bin/musescore\")\n",
    "environment.set(\"musicxmlPath\", \"/usr/bin/musescore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore.mscore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore.mscore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext music21.ipython21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルな例からスタート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoDownload:\n",
      "ask\n",
      "braillePath:\n",
      "None\n",
      "debug:\n",
      "0\n",
      "directoryScratch:\n",
      "None\n",
      "graphicsPath:\n",
      "None\n",
      "ipythonShowFormat:\n",
      "ipython.musicxml.png\n",
      "lilypondBackend:\n",
      "ps\n",
      "lilypondFormat:\n",
      "pdf\n",
      "lilypondPath:\n",
      "/home/toshinao/PycharmProjects/deepjazz_in_a_file/lilypond\n",
      "lilypondVersion:\n",
      "None\n",
      "localCorporaSettings:\n",
      "{}\n",
      "localCorpusPath:\n",
      "localCorpusSettings:\n",
      "LocalCorpusSettings([])\n",
      "manualCoreCorpusPath:\n",
      "None\n",
      "midiPath:\n",
      "None\n",
      "musescoreDirectPNGPath:\n",
      "/usr/bin/musescore\n",
      "musicxmlPath:\n",
      "/usr/bin/musescore\n",
      "pdfPath:\n",
      "None\n",
      "showFormat:\n",
      "musicxml\n",
      "vectorPath:\n",
      "None\n",
      "warnings:\n",
      "1\n",
      "writeFormat:\n",
      "musicxml\n"
     ]
    }
   ],
   "source": [
    "from music21 import environment\n",
    "settings = environment.UserSettings()\n",
    "for key in sorted(settings.keys()):\n",
    "    print(key + \":\")\n",
    "    if key is not 'localCorpusPath':\n",
    "        print(settings[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note\n",
    "### noteの追加\n",
    "\n",
    "insert works as expected if it is \"Note to Stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SubConverterFileIOException",
     "evalue": "png file of xml not found. Or file >999 pages?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSubConverterFileIOException\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-dce44b13639c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mst1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/music21/stream/__init__.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misSorted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoSort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# --------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/music21/base.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, fmt, app, **keywords)\u001b[0m\n\u001b[1;32m   2628\u001b[0m                                  \u001b[0mapp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                  \u001b[0msubformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubformats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m                                  **keywords)\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/music21/converter/subConverters.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, obj, fmt, app, subformats, **keywords)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 fp = helperSubConverter.write(s, helperFormat,\n\u001b[0;32m--> 360\u001b[0;31m                                               subformats=helperSubformats, **keywords)\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhelperSubformats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/music21/converter/subConverters.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, obj, fmt, fp, subformats, **keywords)\u001b[0m\n\u001b[1;32m    936\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubformats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 and not str(environLocal['musescoreDirectPNGPath']).startswith('/skip')):\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunThroughMusescore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubformats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/music21/converter/subConverters.py\u001b[0m in \u001b[0;36mrunThroughMusescore\u001b[0;34m(self, fp, subformats, **keywords)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubformatExtension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindPNGfpFromXMLfp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpOut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfpOut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/music21/converter/subConverters.py\u001b[0m in \u001b[0;36mfindPNGfpFromXMLfp\u001b[0;34m(self, xmlFilePath)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             raise SubConverterFileIOException(\n\u001b[0;32m--> 807\u001b[0;31m                 'png file of xml not found. Or file >999 pages?')\n\u001b[0m\u001b[1;32m    808\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpngfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSubConverterFileIOException\u001b[0m: png file of xml not found. Or file >999 pages?"
     ]
    }
   ],
   "source": [
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "位置を指定して挿入する場合はinsertを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B-4\"))\n",
    "st1.insert(1,note.Note(\"B-4\"))\n",
    "st1.insert(2,note.Note(\"B#3\"))\n",
    "st1.insert(3,note.Note(\"B#3\"))\n",
    "st1.insert(4 , note.Note(\"B3\"))\n",
    "st1.insert(4 , note.Note(\"B2\"))\n",
    "st1.insert(5 , note.Note(\"C4\"))\n",
    "st1.insert(9 , note.Note(\"C4\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appendは最後に追加してくれるので位置の指定をしなくてよくて便利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.append(note.Note(\"C4\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwv295 = corpus.parse('bach/bwv295')\n",
    "bwv295.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音のシフト\n",
    "C4をMajor 3rd(長三度)だけシフトした音すなわちE4を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0 , note.Note(\"C4\"))\n",
    "st1.insert(6 , note.Note(\"C4\").transpose(\"M3\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E4をdouble diminished 6th（重減６度？）だけシフトした音を追加。\n",
    "ただし、double diminishedやdouble augumentedが実際に使われることはまれとのこと。\n",
    "（https://en.wikipedia.org/wiki/Interval_(music)#Main_intervals\n",
    "を参照。日本語版wikipediaはいまいちなので英語版を見ること）\n",
    "\n",
    "\n",
    "\n",
    "その他の参考URL：\n",
    "\n",
    "http://guitarchord-lab.com/theory/interval.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"E4\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"dd6\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、例えばC4の重減六度なるものは存在しないっぽい。したがって普通にラ（長６度・Major 6th）がappendされてしまう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"dd6\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして６度には完全６度というものは存在しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.append(note.Note(\"C4\").transpose(\"P6\")) #returns error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完全５度がなぜ完全ともみなされてきたか？それはドとソの周波数比がほぼほぼ2:3になっているから。\n",
    "すなわち、$2^{7/12}\\approx 1.5$であるから："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**(7/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に完全４度はほぼほぼ３：４になっている。すなわち、\n",
    "$2^{5/12}\\approx\\frac{4}{3}$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**(5/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（時間的な）offsetの範囲を調べるには以下のようにすればいいだろう（？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"E4\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"dd6\"))\n",
    "max_offset = max([x.offset for x in st1])\n",
    "print(max_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に付け加えるのをinsertでやるのであれば、以下のようにすればよいだろう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.insert(max_offset + 1 , note.Note(\"C3\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appendは以下のようにまとめて行うことができる（ただし、和音を付け加えるような動作ではない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.append([note.Note(\"D4\") , note.Note(\"E4\")])\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のように和音を追加することはできない・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.insert(max_offset + 1 , [note.Note(\"D4\") , note.Note(\"E4\")]) #returns error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あるoffsetの範囲を切り取るには・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.getElementsByOffset(0,4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、ヒエラルヒーがある場合の切り取り方はまだ試行削除中・・"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音の高さの差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 半音を100とするfloatで取出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval.notesToChromatic(note.Note(\"D5\") , note.Note(\"D#4\")).cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_diff = interval.notesToChromatic(note.Note(\"D4\") , note.Note(\"D4#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff.cents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.Note(\"C0\").transpose(1).nameWithOctave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音の大きさ（velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= note.Note(\"B-4\")\n",
    "n.volume.velocity = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テンポ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_score = stream.Score()\n",
    "bpm = 180\n",
    "run_score.insert(0.0, tempo.MetronomeMark(number=bpm)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音のoffset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "floatで指定されている場合とfraction.fractionで指定されている場合があるので統計処理する場合はfloat()でcastしてやる必要がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 楽器の指定、key signature（調記号・調号）の追加など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3=stream.Stream()\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(instrument.ElectricGuitar())\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(instrument.Piano())\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(key.KeySignature(1))\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(key.KeySignature(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記でいいのか？\n",
    "(慣習的にどうかはともかく入力として許容されるのか？)\n",
    "\n",
    "↑たぶんダメ。楽器はinsertで指定すべき！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3.getInstrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in st3.getInstruments()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 楽器名の文字列での取り出し方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3.getInstrument().instrumentName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score, part, measureについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scoreとPartとMeasureがstreamの基本的なsubclass\n",
    "\n",
    "scoreがpartを複数含み、partはmeasureを複数持つ、というのが基本的なScoreの構成（deep jazzの例のようにそうでないヒエラルヒーを持つ場合もある）。\n",
    "この「基本的な構成」を持つ例としてバッハの楽譜xmlファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bach = corpus.parse('bach/bwv65.2.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このscoreは４つのPartから構成される。\n",
    "\n",
    "各Partは各楽器に対応していて、それぞれひとつずつPartがある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(x) for x in s_bach.getElementsByClass(stream.Stream)] #a lot of \"Part\"s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このBachの例ではPartはmeasure(小節)から成る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\" \".join([str(type(y)) for y in x.getElementsByClass(stream.Stream)]) for x in s_bach.getElementsByClass(stream.Stream)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、\n",
    "\n",
    "http://web.mit.edu/music21/doc/usersGuide/usersGuide_06_stream2.html\n",
    "\n",
    "に注意があるように、PartはtimeSignatureやkeySignatureなども格納できるので、getElementByClassでアクセスするほうが安全:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([x for x in s_bach]))\n",
    "print(len([type(x) for x in s_bach.getElementsByClass(stream.Stream)] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### appendの動作\n",
    "noteを追加すると後ろに音を追加\n",
    "streamのsubclassを追加した場合はヒエラルヒーを構成する、けれど時間的順序はnoteを追加した場合と同じ？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.append(note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st0.append(st1)\n",
    "st0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.append(note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.append(st0)\n",
    "st2.append(st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.insert(0, note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.insert(0,note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.append(st0)\n",
    "st2.append(st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.insert(0, note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.insert(0,note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.insert(0 , st0)\n",
    "st2.insert(0, st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のヒエラルヒーと異なる構造を持つ例\n",
    "\n",
    "deepjazzの例では\n",
    "\n",
    "Score (midi_data) > Part (melody_stream) > Voice (melody1,2 , melody_voice) ＞ Note\n",
    "\n",
    "という階層に従ってデータを切り出しているように見える。\n",
    "すなわちPartはMeasureを持たず、その代わり（？）にVoice(声)を持っている："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz = converter.parse('C:/Users/t/PycharmProjects/deepjazz_in_a_file/midi/original_metheny.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_parts = [x for x in s_jazz.getElementsByClass(stream.Part)]\n",
    "len(s_jazz_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partは楽器が指定してあったりなかったり。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.getInstrument() for x in s_jazz.getElementsByClass(stream.Part)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices = [x for x in s_jazz_parts[0].getElementsByClass(stream.Voice)]\n",
    "len(s_jazz_part0_voices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partの構成要素であるvoiceにも同様にinstrumentが指定してあったりしなかったり。おそらく、partレベルで指定しておき、それが構成要素であるvoiceに遺伝している形か"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.getInstrument() for x in s_jazz_parts[a].getElementsByClass(stream.Voice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VoiceのなかにMeasureがあるかと思いきやそんなものはない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_jazz_part0_voices[0].getElementsByClass(stream.Measure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではなにが入っているかといえば、（ScoreのなかのPartのなかの）各PartのVoice[0]はおおむねChordから構成されている（他はnote.Rest, note.Noteが少々）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"   \".join([str(type(x)) for x in s_jazz_part0_voices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おそらく各パートのvoice[1]以降はおおむねnoteから構成されている（？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "であるが、deepjazzでchordパートを切り出す際にはそのように決め打つことなく、solo_stream[0]からremoveByClassでnoteを除外しつつすべてのchordを抽出している。\n",
    "また、melodyパートはsolo_stream[-1]から特に除外操作をすることなくすべてのnoteを抽出できている（？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"   \".join([str(type(x)) for x in s_jazz_part0_voices[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.mathgram.xyz/entry/plotly の下のほうを参考に（上の方は冗長）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get melody part, compress into single voice.\n",
    "melody_stream = s_jazz[5]     # For Metheny piece, Melody is Part #5.\n",
    "melody1, melody2 = melody_stream.getElementsByClass(stream.Voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly as offline mode\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "offline.init_notebook_mode(connected=False)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "columns = iris.feature_names\n",
    "\n",
    "# make dataframe\n",
    "df = pd.DataFrame(iris.data, columns=columns)\n",
    "\n",
    "# make trace\n",
    "trace = go.Scatter(\n",
    "    x = np.array([float(j.offset) for j in melody1][0:1000]),\n",
    "    y = np.array([float(j.offset) for j in melody2][0:1000]),\n",
    "    mode = \"markers\")\n",
    "\n",
    "# define layout\n",
    "layout = go.Layout(\n",
    "    showlegend=False)\n",
    "\n",
    "data = [trace]\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voice（声）とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q125207687\n",
    "参照。\n",
    "- 例えば合唱であれば、３声というのは三人で歌っているイメージ。\n",
    "- ピアノの場合、おなじことをひとりでできてしまうので単一のピアノパートのなかに複数のvoiceがありえる（ということか？）\n",
    "\n",
    "さらに推理すれば、\n",
    "\n",
    "- midiのなかのpartの分け方に恣意性はないが、そのなかのvoiceへの切り方には恣意性がある（切り分け方を変えても出てくる音は変わらない）ために、partのなかのvoiceはそもそもmergeすべき存在であると言えるか\n",
    "- メセニーの例でもパート５に存在するふたつのvoiceを「すべて」マージしてしまっている\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accompaniment  (伴奏) part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メセニーの例ではパート0,1,6,7が伴奏パートとのこと。\n",
    "- ではそれ以外は？？？\n",
    "- その他の多くのパートには楽器が登録されていない。\n",
    "- ただし、パート１１はパートゼロと同じくピアノがアサインされている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パート２はなにか意味があるような内容に見えるが・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz[2].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他方、パート１１はずっとソ＃をたたいているだけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz[11].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フラット化\n",
    "\n",
    "フラット化してもクラスは変わらない。すなわち、\n",
    "+ stream.Streamをフラットにするとフラットなstream.Streamが\n",
    "+ stream.Scoreをフラットにするとフラットなstream.Scoreが\n",
    "\n",
    "できることになる。\n",
    "\n",
    "そして、それぞれダイレクトにnoteが収納されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([str(type(x)) for x  in s_bach.flat.getElementsByClass(note.Note)])#example of how to flatten the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([str(type(x)) for x  in s_jazz.flat.getElementsByClass(note.Note)])#example of how to flatten the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(s_bach.flat))#score\n",
    "print(type(s_jazz.flat))#score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flat化およびvoice, partの使い分けについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flat化してひとつのvoiceに収納することが例えばdeep learningに突っ込むための合理的な前処理 \n",
    "- ただし、複数の楽器をまとめたオブジェクトの構成部品はpartでなくてはならない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chord（和音）について\n",
    "\n",
    "ChordもNoteもGeneralNoteの派生クラス\n",
    "\n",
    "参考URL：\n",
    "http://web.mit.edu/music21/doc/moduleReference/moduleNote.html#music21.note.GeneralNote\n",
    "\n",
    "deep jazzの解明のためにはChord、すなわち「和音」の理解が重要そうなので少し深堀してみる\n",
    "\n",
    "参考URL:\n",
    "http://web.mit.edu/music21/doc/usersGuide/usersGuide_07_chords.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chord（和音）の作り方："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor = chord.Chord([\"C4\", \"G4\",\"E-5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cMinor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pitch(音高)\n",
    "noteにはpitch（音高）があるが、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.Note(\"C4\").pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chord（和音）にはpitchはない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.pitch # returns errof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのかわりpitchesがある："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MajorかMinorか\n",
    "MajorかMinorかを判別してくれるメソッドはこれ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMajorTriad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英和対応：\n",
    "+ triad : 三和音\n",
    "+ major triad : 長三和音\n",
    "+ minor triad : 短三和音"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語wikipedia\n",
    "https://ja.wikipedia.org/wiki/%E7%9F%AD%E4%B8%89%E5%92%8C%E9%9F%B3\n",
    "によれば、短三和音は\n",
    "+ base\n",
    "+ base + m3\n",
    "+ base + P5\n",
    "によって構成される三和音とのことだが・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMinorTriad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "はTrueになるのでisMinorTriadの判定基準は日本語wikipediaの定義と異なる？\n",
    "\n",
    "というより、オクターブの違いは無視している(すわわちmod 12)ということか?\n",
    "\n",
    "より近接した音で構成される和音に変えるには以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.closedPosition().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コードの「名前」を知りたければ以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cMinor.commonName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メソッドisMajorTriadが何をやっているかは以下で解明できるはず：（だがスキップして先に進もう）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMajorTriad??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドミソをミソドにしたようなのを展開形という。展開形かどうかのチェックは以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.inversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale(音階)について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType = scale.MajorScale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://web.mit.edu/music21/doc/moduleReference/moduleScale.html\n",
    "\n",
    "によれば\n",
    "\n",
    "ConcreteScale.derive(other, comparisonAttribute='pitchClass')\n",
    "\n",
    "Return the closest-matching ConcreteScale based on the pitch collection provided as a Stream, a ConcreteScale, or a list of Pitch objects.\n",
    "\n",
    "要は音階がドミソ（すべて白鍵）ならドレミファソラシド（すべて白鍵）が含まれているC Major音階と推定するような感じか。\n",
    "推定アルゴリズムは変化の可能性ありと公式ウェブにも書いてある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType.derive(cMinor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = scale.MinorScale().derive(cMinor)\n",
    "scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定されたscaleに含まれる音を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([pitch for pitch in scales.getPitches()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドリアンスケールの場合の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType = scale.DorianScale()\n",
    "scales = scaleType.derive(cMinor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微分音（microtonal)\n",
    "\n",
    "参考URL:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Microtonal_music\n",
    "\n",
    "https://groups.google.com/forum/#!topic/music21list/-8PTr2gU8Hs\n",
    "\n",
    "http://web.mit.edu/music21/doc/moduleReference/modulePitch.html#music21.pitch.Pitch.convertMicrotonesToQuarterTones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他の基本的なscoreに対する操作(あまり必要ないかも)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.analyze('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tinynotationについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = converter.parse(\"tinynotation: 3/4 c4 d8 f g16 a g f#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = stream.Stream()\n",
    "s2.insert(0  , p)#adding part, first argument should be offset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=converter.parse(\"tinynotation: c4 d8 f g16 a g f#\")\n",
    "s2.insert(100,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=converter.parse(\"tinynotation: c4 d8 f g16 a g f#\")\n",
    "s2.insert(10,r)\n",
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.insert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?s2.insert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
