{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git commit -a -m \"checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.rileynwong.com/blog/2019/2/25/generating-music-with-an-lstm-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bokeh initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.transform import jitter\n",
    "import bokeh.plotting as bp\n",
    "from bokeh import palettes\n",
    "bp.output_notebook()\n",
    "from bokeh.models import ColumnDataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparation I wrote  (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(l, n):\n",
    "    \"\"\"\n",
    "    リストをサブリストに分割する\n",
    "    :param l: リスト\n",
    "    :param n: サブリストの要素数\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    for idx in range(0, len(l), n):\n",
    "        yield l[idx:idx + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notes_list = []\n",
    "note_set = set()\n",
    "for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "    run_notes = []\n",
    "    print(file)\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    if parts: # file has instrument parts\n",
    "        #Pdb().set_trace()\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            run_notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            Pdb().set_trace()\n",
    "            #Pdb().set_trace()\n",
    "            run_notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    note_set = note_set | set(run_notes)\n",
    "    for n in split_list(run_notes , max_sequence_length):\n",
    "        if len(n) > 10:\n",
    "            notes_list.append(n)\n",
    "    #notes_list.append(run_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to be ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as in tutorial on the web (to be skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "notes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "notes = []\n",
    "for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "    print(file)\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    if parts: # file has instrument parts\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example : when there is only one midi file (to be skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"midi/sonate_31.mid\"\n",
    "file = 'chorales/midi/065900b_.mid'\n",
    "midi = converter.parse(file)\n",
    "notes_to_parse = None\n",
    "notes = []\n",
    "parts = instrument.partitionByInstrument(midi)\n",
    "if parts: # file has instrument parts\n",
    "    notes_to_parse = parts.parts[0].recurse()\n",
    "else: # file has notes in a flat structure\n",
    "    notes_to_parse = midi.flat.notes\n",
    "for element in notes_to_parse:\n",
    "    if isinstance(element, note.Note):\n",
    "        notes.append(str(element.pitch))\n",
    "    elif isinstance(element, chord.Chord):   \n",
    "        run_chord = element\n",
    "        notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flat notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_notes = [x for x in midi.flat.notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note = flat_notes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [x.offset for x in midi.flat.notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 頻度チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = pd.DataFrame({'x' : notes[0:-1] , 'y':notes[1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = run_df.assign(z = run_df.x + ' ' +  run_df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(run_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_range = list(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure(x_range = run_range , y_range = run_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.scatter(jitter('x' , width = 0.5 , range = p.x_range) , jitter('y' , width = 0.5 , range = p.y_range) , source = source )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 差分に基づくデータ記述の試み(20191022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数化済みバージョン\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score2df import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'score2df' from '/home/toshinao/PycharmProjects/deepjazz_in_a_file/score2df.py'>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mscore2df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore2df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "create data frame from midi file\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "file : string\n",
       "    file path to a midi file\n",
       "\n",
       "Returns\n",
       "-------\n",
       "pandas data frame whose columns are\n",
       "    pitch : pitch of each note\n",
       "    time : time from the start of each note\n",
       "    cent : pitch as interger relative to C4\n",
       "    n : for example, 1 if a note is the second from the lowest among the simultaneously pressed notes\n",
       "    dcent: the difference of cent from the previous note after grouping by n\n",
       "\u001b[0;31mFile:\u001b[0m      ~/PycharmProjects/deepjazz_in_a_file/score2df.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?score2df.score2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = score2df.score2df(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>time</th>\n",
       "      <th>cent</th>\n",
       "      <th>n</th>\n",
       "      <th>dcent</th>\n",
       "      <th>dcent_lag1</th>\n",
       "      <th>dcent_lag2</th>\n",
       "      <th>dcent_lag3</th>\n",
       "      <th>dtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G3</td>\n",
       "      <td>1</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pitch time    cent  n  dcent  dcent_lag1  dcent_lag2  dcent_lag3 dtime\n",
       "0    G2    0 -1700.0  0    NaN         NaN         NaN         NaN   NaN\n",
       "1    A2  0.5 -1500.0  0  200.0         NaN         NaN         NaN   0.5\n",
       "3   B-2    1 -1400.0  0  100.0       200.0         NaN         NaN   0.5\n",
       "2    G3    1  -500.0  1    NaN         NaN         NaN         NaN   NaN\n",
       "4    C3  1.5 -1200.0  0  200.0       100.0       200.0         NaN   0.5"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2df.add_lags(df_score).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>time</th>\n",
       "      <th>cent</th>\n",
       "      <th>n</th>\n",
       "      <th>dcent</th>\n",
       "      <th>dcent_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G3</td>\n",
       "      <td>1</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pitch time    cent  n  dcent  dcent_lag1\n",
       "0    G2    0 -1700.0  0    NaN         NaN\n",
       "1    A2  0.5 -1500.0  0  200.0         NaN\n",
       "3   B-2    1 -1400.0  0  100.0       200.0\n",
       "2    G3    1  -500.0  1    NaN         NaN\n",
       "4    C3  1.5 -1200.0  0  200.0       100.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = df_score.assign(dcent_lag1 = df_score.groupby('n').dcent.shift(1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dplyr::spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/mwmsnn/items/6a464865759231aa888d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベタ打ちバージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"midi/sonate_31.mid\"\n",
    "file = 'chorales/midi/065900b_.mid'\n",
    "midi = converter.parse(file)\n",
    "notes_to_parse = None\n",
    "max_simultaneous = 4\n",
    "#pitches = [[] for i in range(max_simultaneous)]\n",
    "#times = [[] for i in range(max_simultaneous)]\n",
    "#diffs = [[] for i in range(max_simultaneous)]\n",
    "pitches = []\n",
    "times = []\n",
    "diffs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = instrument.partitionByInstrument(midi)\n",
    "if parts: # file has instrument parts\n",
    "    notes_to_parse = parts.parts[0].recurse()\n",
    "else: # file has notes in a flat structure\n",
    "    notes_to_parse = midi.flat.notes\n",
    "for element in notes_to_parse:\n",
    "    \n",
    "    if isinstance(element, note.Note):        \n",
    "        #run_notes = [element]\n",
    "        pitches.append(str(element.pitch))\n",
    "        diffs.append(interval.notesToChromatic(note.Note(\"C4\") , element).cents)\n",
    "        times.append(element.offset)\n",
    "    elif isinstance(element, chord.Chord):           \n",
    "        run_chord = element\n",
    "        for i in range(min(len(element.normalOrder) , max_simultaneous)):\n",
    "            pitches.append(element.pitches[i])\n",
    "            diffs.append(interval.notesToChromatic(note.Note(\"C4\") , run_chord.notes[i]).cents)\n",
    "            times.append(element.offset)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame({'pitch' : pitches , 'time' : times , 'cent' : diffs })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.sort_values(['time' , 'cent'] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = df_score.assign(n = df_score.groupby('time').cumcount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df_score[df_score.n == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_score[df_score.n == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.assign(dcent = df0.cent.diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.assign(dcent_lag1 = df0.dcent.shift(1))\n",
    "df0 = df0.assign(dcent_lag2 = df0.dcent.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap , geom_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df0 , aes(x = 'dcent / 200')) + geom_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dcentの値域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df0['dcent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "たかだか７１とか（もともとのnoteの数より少ない？）なので離散化してもなんとかなりそう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dcentは自己相関がありそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df0 , aes(x = 'dcent / 200' , y = 'dcent_lag1 / 200')) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.statsmodels.org/dev/example_formulas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = 'dcent ~ dcent_lag1' , data = df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  dcent   R-squared:                       0.367\n",
      "Model:                            OLS   Adj. R-squared:                  0.366\n",
      "Method:                 Least Squares   F-statistic:                     283.5\n",
      "Date:                Sat, 26 Oct 2019   Prob (F-statistic):           1.72e-50\n",
      "Time:                        15:47:44   Log-Likelihood:                -4196.5\n",
      "No. Observations:                 490   AIC:                             8397.\n",
      "Df Residuals:                     488   BIC:                             8405.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.4017     57.406      0.059      0.953    -109.391     116.194\n",
      "dcent_lag1    -0.6062      0.036    -16.838      0.000      -0.677      -0.535\n",
      "==============================================================================\n",
      "Omnibus:                        7.416   Durbin-Watson:                   2.551\n",
      "Prob(Omnibus):                  0.025   Jarque-Bera (JB):                7.275\n",
      "Skew:                          -0.286   Prob(JB):                       0.0263\n",
      "Kurtosis:                       3.172   Cond. No.                     1.59e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.59e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### momentumもありそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = 'dcent ~ dcent_lag1 + dcent_lag2' , data = df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  dcent   R-squared:                       0.498\n",
      "Model:                            OLS   Adj. R-squared:                  0.496\n",
      "Method:                 Least Squares   F-statistic:                     241.3\n",
      "Date:                Sat, 26 Oct 2019   Prob (F-statistic):           1.69e-73\n",
      "Time:                        15:48:56   Log-Likelihood:                -4131.8\n",
      "No. Observations:                 489   AIC:                             8270.\n",
      "Df Residuals:                     486   BIC:                             8282.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.0440     51.288      0.098      0.922     -95.729     105.817\n",
      "dcent_lag1    -0.8818      0.040    -21.825      0.000      -0.961      -0.802\n",
      "dcent_lag2    -0.4546      0.040    -11.251      0.000      -0.534      -0.375\n",
      "==============================================================================\n",
      "Omnibus:                        0.336   Durbin-Watson:                   2.228\n",
      "Prob(Omnibus):                  0.845   Jarque-Bera (JB):                0.402\n",
      "Skew:                           0.060   Prob(JB):                        0.818\n",
      "Kurtosis:                       2.926   Cond. No.                     2.02e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.02e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.scatter(df0.cent , df0.dcent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.scatter('cent' , 'dcent' , source = source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_list = [x for x in notes_to_parse if isinstance(x , note.Note)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(note_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note = note_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(a_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_note.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding new flow (main)\n",
    "\n",
    "https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
    "に概ね準拠仕様と思ったが・・・\n",
    "\n",
    "- そもそもlabelencoder -> onehot  は今後必要ないよとwarning が出る\n",
    "- onehot の挙動が読みにくい\n",
    "\n",
    "のでlabelencodingしたあと直にnp.arrayをmanual onehote化したほうがいいのではないか？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(list(note_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_notes_list = [le.transform(np.array(x)) for x in notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set(le.transform(list(note_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = [torch.zeros(labeled_notes_list[i].shape[0] - 1 , len(label_set)) for i in range(len(notes_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(notes_list)):\n",
    "    for j in range(labeled_notes_list[i].shape[0]-1):\n",
    "        raw_X[i][j , labeled_notes_list[i][j]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_X = torch.nn.utils.rnn.pack_sequence(raw_X , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X = torch.nn.utils.rnn.pad_packed_sequence(packed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_y = [torch.tensor(np.array(x[1:])) for x in labeled_notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_y = torch.nn.utils.rnn.pack_sequence(raw_y , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_y = torch.nn.utils.rnn.pad_packed_sequence(packed_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding previous flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohnotes = ohe.fit_transform(np.array(notes).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohnotes = ohe.fit(np.array(list(note_set)).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohnotes_list = [ohe.transform(np.array(x).reshape(-1,1)) for x in notes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ohnotes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = [torch.Tensor(x.toarray()) for x in ohnotes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_X = torch.nn.utils.rnn.pack_sequence(raw_X , enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X = torch.nn.utils.rnn.pad_packed_sequence(packed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference\n",
    "\n",
    "- OneHotEncoderだけでいける。LabelEncoderをかます必要なしと当初思っていたがむしろ逆\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n",
    "\n",
    "Another possible good reference:\n",
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obsolete : label encoder: 不必要という判断になっていたが結局こちらのほうがいいかも？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(list(note_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inotes = le.transform(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inotes[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.Tensor([len(x) - 1 for x in notes_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ppd_X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM\n",
    "\n",
    "参考文献のpreprocessはあまり納得いかないので・・\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "をみつつやってみるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  復習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "sequence_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(sequence_length, sequence_num, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(num_layers , sequence_num , hidden_size)\n",
    "c0 = torch.randn(num_layers , sequence_num, hidden_size)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputの最後尾（sequence length方向の末尾）とhnは一致する:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 復習２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = ppd_X[0][: , 0:10 ]\n",
    "batch_y = ppd_y[0][:,  0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_num = batch_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(num_layers , sequence_num , hidden_size)\n",
    "c0 = torch.randn(num_layers , sequence_num, hidden_size)\n",
    "output, (hn, cn) = rnn(batch_X, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_size = len(ohe.get_feature_names())\n",
    "hidden_size = 50\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ppd_X[0].shape[2]\n",
    "hidden_size = ppd_X[0].shape[2]\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(my_model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
    "\n",
    "        #self.linear = nn.Linear(hidden_size, input_size) #output dimension has to be identical with the input dimension\n",
    "        #self.softmax = nn.functional.softmax()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        sequence_num = input.shape[1]\n",
    "        self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input, (self.h0, self.c0))\n",
    "        #y = self.linear(y)\n",
    "        y = nn.functional.softmax(y , dim = 2)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献に似せたモデル\n",
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "に似せたモデル\n",
    "現状ランダムの1.8倍程度の正答率にしかならない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ppd_X[0].shape[2]\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers , dropout):\n",
    "        #super(my_model, self).__init__()\n",
    "        \n",
    "        super().__init__()\n",
    "        #self.input_size = input_size\n",
    "        #self.hidden_size = hidden_size\n",
    "        #self.num_layers = num_layers\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers , dropout=dropout)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, input_size) #output dimension has to be identical with the input dimension\n",
    "      \n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        #self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        #self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input)#, (self.h0, self.c0))\n",
    "        y = self.linear(y)\n",
    "        y = self.relu1(y)\n",
    "        y = nn.functional.softmax(y , dim = 2)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size , hidden_size , num_layers , dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp = model.forward(ppd_X[0][:, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy for one-hot representation\n",
    "https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/4\n",
    "\n",
    "one-hotのままでなくて、Rでいうところのfactorに戻したほうがよさそう（？）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "input has to be a Tensor of size either (minibatch, C)(minibatch,C) or (minibatch, C, d_1, d_2, ..., d_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crossentropyの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplest example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = criterion(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まとめて評価する場合（ただし、maskの適用方法がopen problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(y_tmp.permute(1 , 2,0 ) , batch_y.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(y_tmp.transpose(0 , 1).transpose(1,2) , batch_y.transpose(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/elm200/items/46633430c456dd90f1e3\n",
    "def try_gpu(e):\n",
    "    if torch.cuda.is_available():\n",
    "        return e.cuda()\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_use_gpu:\n",
    "    model = try_gpu(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ppd_X[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = range( 0 ,sample_size ,  batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_when_random = 1 / len(note_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(n_epochs):\n",
    "    batch_loss = 0\n",
    "    shuffled_idx = torch.randperm(sample_size)\n",
    "    for i in batch_indices:\n",
    "        #display(\".\")\n",
    "        batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]\n",
    "\n",
    "        batch_X = ppd_X[0][: , batch_samples]\n",
    "        batch_y = ppd_y[0][:,  batch_samples]        \n",
    "        batch_mask = mask[batch_samples]\n",
    "        \n",
    "        if is_use_gpu:\n",
    "            batch_X = try_gpu(batch_X)\n",
    "            batch_y = try_gpu(batch_y)\n",
    "\n",
    "            batch_mask = try_gpu(batch_mask)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch_y_model = model(batch_X)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for j in range(batch_y.shape[1]):\n",
    "            loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    batch_loss /= torch.sum(mask).item()\n",
    "    losses.append(batch_loss)\n",
    "    mean_correct_prob = np.exp(-batch_loss)\n",
    "    \n",
    "    \n",
    "    display(\"epoch : {}   loss : {}   correct prob : {} correct / random : {}\".format(k , batch_loss ,\n",
    "                                                                        mean_correct_prob ,\n",
    "                                                                        mean_correct_prob / prob_when_random))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/jyori112/items/aad5703c1537c0139edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict() , 'saved/model20191022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = 0\n",
    "for i in batch_indices:\n",
    "    #display(\".\")\n",
    "    batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]\n",
    "\n",
    "    batch_X = ppd_X[0][: , batch_samples]\n",
    "    batch_y = ppd_y[0][:,  batch_samples]\n",
    "\n",
    "    batch_mask = mask[batch_samples]\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    batch_y_model = model(batch_X)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for j in range(batch_y.shape[1]):\n",
    "        loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])\n",
    "    batch_loss += loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    display(batch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one batch toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = batch_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = ppd_X[0][: , batch_samples]\n",
    "batch_y = ppd_y[0][:,  batch_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mask = mask[batch_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_model = model(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "\n",
    "for j in range(batch_y.shape[1]):\n",
    "    loss += criterion( batch_y_model[0:batch_mask[j] , j ] , batch_y[0:batch_mask[j] , j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_model[0:batch_mask[j] , j ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y[0:batch_mask[j] , j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(y_tmp.permute(1 , 2,0 )[j , :, 0 : batch_mask[j]] , batch_y.transpose(0,1)[ j , 0 : batch_mask[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my own try and error　（この節のプロセスは必要ない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://d.hatena.ne.jp/naraba/20121201/p1\n",
    "#http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html\n",
    "\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set('musicxmlPath' , r\"C:\\Program Files (x86)\\Finale NotePad 2012\\Finale NotePad.exe\")\n",
    "#configure.run()\n",
    "#environment.keys()\n",
    "#environment.get('musicxmlPath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = corpus.parse('bach/bwv65.2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.analyze('key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[type(x) for x in s.getElementsByClass(stream.Stream)] #a lot of \"Part\"s\n",
    "[[print(type(y)) for y in x.getElementsByClass(stream.Stream)] for x in s.getElementsByClass(stream.Stream)]\n",
    "[print(x) for x  in s.flat.getElementsByClass(note.Note)]#example of how to flatten the score\n",
    "#unlike the deepjazz example, each Parts consists of \"Measure\"s\n",
    "type(s)#score\n",
    "\n",
    "#scoreとPartとMeasureがstreamの基本的なsubclass\n",
    "#scoreがpartを複数含み、partはmeasureを複数持つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting the note...\n",
    "Useful tips for jupyter notebook:\n",
    "\n",
    "https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://d.hatena.ne.jp/naraba/20121201/p1\n",
    "#http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html\n",
    "\n",
    "from music21 import *\n",
    "#environment.set('musicxmlPath' , r\"C:\\Program Files (x86)\\Finale NotePad 2012\\Finale NotePad.exe\")\n",
    "#configure.run()\n",
    "#environment.keys()\n",
    "#environment.get('musicxmlPath')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "楽譜を表示するためのおまじない\n",
    "\n",
    "参考URL:https://groups.google.com/forum/#!topic/music21list/FmU6HeNm7AM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = environment.UserSettings() #不必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'\n",
    "us['musescoreDirectPNGPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install musescore in linux (apt-getでインストールするのがポイント）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all those who will struggle with displaying scores from music21 within Jupyter Notebook on Linux (e.g. Ubuntu), follow these steps:\n",
    "https://stackoverflow.com/questions/49939275/python-music21-library-create-png-from-stream/49945456#49945456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MuseScoreのバージョンが2から3にあがっていたので、初期設定のままではうごきませんでした。\n",
    "https://qiita.com/nofrmm/items/c3662555b145f6b42d92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set(\"musescoreDirectPNGPath\", \"/usr/bin/musescore\")\n",
    "#environment.set(\"musicxmlPath\", \"/snap/bin/musescore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore.mscore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore.mscore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext music21.ipython21　#不必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルな例からスタート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note\n",
    "### noteの追加\n",
    "\n",
    "insert works as expected if it is \"Note to Stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "位置を指定して挿入する場合はinsertを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0,note.Note(\"B-4\"))\n",
    "st1.insert(1,note.Note(\"B-4\"))\n",
    "st1.insert(2,note.Note(\"B#3\"))\n",
    "st1.insert(3,note.Note(\"B#3\"))\n",
    "st1.insert(4 , note.Note(\"B3\"))\n",
    "st1.insert(4 , note.Note(\"B2\"))\n",
    "st1.insert(5 , note.Note(\"C4\"))\n",
    "st1.insert(9 , note.Note(\"C4\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appendは最後に追加してくれるので位置の指定をしなくてよくて便利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.append(note.Note(\"C4\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音のシフト\n",
    "C4をMajor 3rd(長三度)だけシフトした音すなわちE4を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.insert(0 , note.Note(\"C4\"))\n",
    "st1.insert(6 , note.Note(\"C4\").transpose(\"M3\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E4をdouble diminished 6th（重減６度？）だけシフトした音を追加。\n",
    "ただし、double diminishedやdouble augumentedが実際に使われることはまれとのこと。\n",
    "（https://en.wikipedia.org/wiki/Interval_(music)#Main_intervals\n",
    "を参照。日本語版wikipediaはいまいちなので英語版を見ること）\n",
    "\n",
    "\n",
    "\n",
    "その他の参考URL：\n",
    "\n",
    "http://guitarchord-lab.com/theory/interval.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"E4\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"dd6\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、例えばC4の重減六度なるものは存在しないっぽい。したがって普通にラ（長６度・Major 6th）がappendされてしまう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"C4\").transpose(\"dd6\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして６度には完全６度というものは存在しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()\n",
    "st1.append(note.Note(\"C4\").transpose(\"P6\")) #returns error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完全５度がなぜ完全ともみなされてきたか？それはドとソの周波数比がほぼほぼ2:3になっているから。\n",
    "すなわち、$2^{7/12}\\approx 1.5$であるから："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**(7/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に完全４度はほぼほぼ３：４になっている。すなわち、\n",
    "$2^{5/12}\\approx\\frac{4}{3}$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**(5/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（時間的な）offsetの範囲を調べるには以下のようにすればいいだろう（？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"E4\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"M6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"m6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"d6\"))\n",
    "st1.append(note.Note(\"E4\").transpose(\"dd6\"))\n",
    "max_offset = max([x.offset for x in st1])\n",
    "print(max_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に付け加えるのをinsertでやるのであれば、以下のようにすればよいだろう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.insert(max_offset + 1 , note.Note(\"C3\"))\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appendは以下のようにまとめて行うことができる（ただし、和音を付け加えるような動作ではない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.append([note.Note(\"D4\") , note.Note(\"E4\")])\n",
    "st1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のように和音を追加することはできない・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.insert(max_offset + 1 , [note.Note(\"D4\") , note.Note(\"E4\")]) #returns error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あるoffsetの範囲を切り取るには・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.getElementsByOffset(0,4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、ヒエラルヒーがある場合の切り取り方はまだ試行削除中・・"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音の高さの差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 半音を100とするfloatで取出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval.notesToChromatic(note.Note(\"D5\") , note.Note(\"D#4\")).cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_diff = interval.notesToChromatic(note.Note(\"D4\") , note.Note(\"D4#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff.cents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.Note(\"C0\").transpose(1).nameWithOctave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音の大きさ（velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= note.Note(\"B-4\")\n",
    "n.volume.velocity = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テンポ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_score = stream.Score()\n",
    "bpm = 180\n",
    "run_score.insert(0.0, tempo.MetronomeMark(number=bpm)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音のoffset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "floatで指定されている場合とfraction.fractionで指定されている場合があるので統計処理する場合はfloat()でcastしてやる必要がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 楽器の指定、key signature（調記号・調号）の追加など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3=stream.Stream()\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(instrument.ElectricGuitar())\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(instrument.Piano())\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(key.KeySignature(1))\n",
    "st3.append(note.Note(\"C4\"))\n",
    "st3.append(key.KeySignature(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記でいいのか？\n",
    "(慣習的にどうかはともかく入力として許容されるのか？)\n",
    "\n",
    "↑たぶんダメ。楽器はinsertで指定すべき！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3.getInstrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in st3.getInstruments()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 楽器名の文字列での取り出し方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3.getInstrument().instrumentName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score, part, measureについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scoreとPartとMeasureがstreamの基本的なsubclass\n",
    "\n",
    "scoreがpartを複数含み、partはmeasureを複数持つ、というのが基本的なScoreの構成（deep jazzの例のようにそうでないヒエラルヒーを持つ場合もある）。\n",
    "この「基本的な構成」を持つ例としてバッハの楽譜xmlファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bach = corpus.parse('bach/bwv65.2.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このscoreは４つのPartから構成される。\n",
    "\n",
    "各Partは各楽器に対応していて、それぞれひとつずつPartがある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(x) for x in s_bach.getElementsByClass(stream.Stream)] #a lot of \"Part\"s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このBachの例ではPartはmeasure(小節)から成る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\" \".join([str(type(y)) for y in x.getElementsByClass(stream.Stream)]) for x in s_bach.getElementsByClass(stream.Stream)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、\n",
    "\n",
    "http://web.mit.edu/music21/doc/usersGuide/usersGuide_06_stream2.html\n",
    "\n",
    "に注意があるように、PartはtimeSignatureやkeySignatureなども格納できるので、getElementByClassでアクセスするほうが安全:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([x for x in s_bach]))\n",
    "print(len([type(x) for x in s_bach.getElementsByClass(stream.Stream)] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### appendの動作\n",
    "noteを追加すると後ろに音を追加\n",
    "streamのsubclassを追加した場合はヒエラルヒーを構成する、けれど時間的順序はnoteを追加した場合と同じ？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.append(note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st0.append(st1)\n",
    "st0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.append(note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.append(note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.append(st0)\n",
    "st2.append(st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.insert(0, note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.insert(0,note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.append(st0)\n",
    "st2.append(st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = stream.Stream()\n",
    "st0.insert(0, note.Note(\"D4\"))\n",
    "st1 = stream.Stream()\n",
    "st1.insert(0,note.Note(\"C4\"))\n",
    "st2 = stream.Stream()\n",
    "st2.insert(0 , st0)\n",
    "st2.insert(0, st1)\n",
    "st2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in st2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のヒエラルヒーと異なる構造を持つ例\n",
    "\n",
    "deepjazzの例では\n",
    "\n",
    "Score (midi_data) > Part (melody_stream) > Voice (melody1,2 , melody_voice) ＞ Note\n",
    "\n",
    "という階層に従ってデータを切り出しているように見える。\n",
    "すなわちPartはMeasureを持たず、その代わり（？）にVoice(声)を持っている："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz = converter.parse('C:/Users/t/PycharmProjects/deepjazz_in_a_file/midi/original_metheny.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_parts = [x for x in s_jazz.getElementsByClass(stream.Part)]\n",
    "len(s_jazz_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partは楽器が指定してあったりなかったり。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.getInstrument() for x in s_jazz.getElementsByClass(stream.Part)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices = [x for x in s_jazz_parts[0].getElementsByClass(stream.Voice)]\n",
    "len(s_jazz_part0_voices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partの構成要素であるvoiceにも同様にinstrumentが指定してあったりしなかったり。おそらく、partレベルで指定しておき、それが構成要素であるvoiceに遺伝している形か"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.getInstrument() for x in s_jazz_parts[a].getElementsByClass(stream.Voice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz_part0_voices[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VoiceのなかにMeasureがあるかと思いきやそんなものはない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_jazz_part0_voices[0].getElementsByClass(stream.Measure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではなにが入っているかといえば、（ScoreのなかのPartのなかの）各PartのVoice[0]はおおむねChordから構成されている（他はnote.Rest, note.Noteが少々）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"   \".join([str(type(x)) for x in s_jazz_part0_voices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おそらく各パートのvoice[1]以降はおおむねnoteから構成されている（？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "であるが、deepjazzでchordパートを切り出す際にはそのように決め打つことなく、solo_stream[0]からremoveByClassでnoteを除外しつつすべてのchordを抽出している。\n",
    "また、melodyパートはsolo_stream[-1]から特に除外操作をすることなくすべてのnoteを抽出できている（？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"   \".join([str(type(x)) for x in s_jazz_part0_voices[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.mathgram.xyz/entry/plotly の下のほうを参考に（上の方は冗長）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get melody part, compress into single voice.\n",
    "melody_stream = s_jazz[5]     # For Metheny piece, Melody is Part #5.\n",
    "melody1, melody2 = melody_stream.getElementsByClass(stream.Voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly as offline mode\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "offline.init_notebook_mode(connected=False)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "columns = iris.feature_names\n",
    "\n",
    "# make dataframe\n",
    "df = pd.DataFrame(iris.data, columns=columns)\n",
    "\n",
    "# make trace\n",
    "trace = go.Scatter(\n",
    "    x = np.array([float(j.offset) for j in melody1][0:1000]),\n",
    "    y = np.array([float(j.offset) for j in melody2][0:1000]),\n",
    "    mode = \"markers\")\n",
    "\n",
    "# define layout\n",
    "layout = go.Layout(\n",
    "    showlegend=False)\n",
    "\n",
    "data = [trace]\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voice（声）とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q125207687\n",
    "参照。\n",
    "- 例えば合唱であれば、３声というのは三人で歌っているイメージ。\n",
    "- ピアノの場合、おなじことをひとりでできてしまうので単一のピアノパートのなかに複数のvoiceがありえる（ということか？）\n",
    "\n",
    "さらに推理すれば、\n",
    "\n",
    "- midiのなかのpartの分け方に恣意性はないが、そのなかのvoiceへの切り方には恣意性がある（切り分け方を変えても出てくる音は変わらない）ために、partのなかのvoiceはそもそもmergeすべき存在であると言えるか\n",
    "- メセニーの例でもパート５に存在するふたつのvoiceを「すべて」マージしてしまっている\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accompaniment  (伴奏) part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メセニーの例ではパート0,1,6,7が伴奏パートとのこと。\n",
    "- ではそれ以外は？？？\n",
    "- その他の多くのパートには楽器が登録されていない。\n",
    "- ただし、パート１１はパートゼロと同じくピアノがアサインされている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パート２はなにか意味があるような内容に見えるが・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz[2].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他方、パート１１はずっとソ＃をたたいているだけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_jazz[11].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フラット化\n",
    "\n",
    "フラット化してもクラスは変わらない。すなわち、\n",
    "+ stream.Streamをフラットにするとフラットなstream.Streamが\n",
    "+ stream.Scoreをフラットにするとフラットなstream.Scoreが\n",
    "\n",
    "できることになる。\n",
    "\n",
    "そして、それぞれダイレクトにnoteが収納されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([str(type(x)) for x  in s_bach.flat.getElementsByClass(note.Note)])#example of how to flatten the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([str(type(x)) for x  in s_jazz.flat.getElementsByClass(note.Note)])#example of how to flatten the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(s_bach.flat))#score\n",
    "print(type(s_jazz.flat))#score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flat化およびvoice, partの使い分けについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flat化してひとつのvoiceに収納することが例えばdeep learningに突っ込むための合理的な前処理 \n",
    "- ただし、複数の楽器をまとめたオブジェクトの構成部品はpartでなくてはならない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chord（和音）について\n",
    "\n",
    "ChordもNoteもGeneralNoteの派生クラス\n",
    "\n",
    "参考URL：\n",
    "http://web.mit.edu/music21/doc/moduleReference/moduleNote.html#music21.note.GeneralNote\n",
    "\n",
    "deep jazzの解明のためにはChord、すなわち「和音」の理解が重要そうなので少し深堀してみる\n",
    "\n",
    "参考URL:\n",
    "http://web.mit.edu/music21/doc/usersGuide/usersGuide_07_chords.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chord（和音）の作り方："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor = chord.Chord([\"C4\", \"G4\",\"E-5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cMinor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pitch(音高)\n",
    "noteにはpitch（音高）があるが、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.Note(\"C4\").pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chord（和音）にはpitchはない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.pitch # returns errof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのかわりpitchesがある："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MajorかMinorか\n",
    "MajorかMinorかを判別してくれるメソッドはこれ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMajorTriad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英和対応：\n",
    "+ triad : 三和音\n",
    "+ major triad : 長三和音\n",
    "+ minor triad : 短三和音"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語wikipedia\n",
    "https://ja.wikipedia.org/wiki/%E7%9F%AD%E4%B8%89%E5%92%8C%E9%9F%B3\n",
    "によれば、短三和音は\n",
    "+ base\n",
    "+ base + m3\n",
    "+ base + P5\n",
    "によって構成される三和音とのことだが・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMinorTriad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "はTrueになるのでisMinorTriadの判定基準は日本語wikipediaの定義と異なる？\n",
    "\n",
    "というより、オクターブの違いは無視している(すわわちmod 12)ということか?\n",
    "\n",
    "より近接した音で構成される和音に変えるには以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.closedPosition().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コードの「名前」を知りたければ以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cMinor.commonName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メソッドisMajorTriadが何をやっているかは以下で解明できるはず：（だがスキップして先に進もう）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.isMajorTriad??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドミソをミソドにしたようなのを展開形という。展開形かどうかのチェックは以下のようにする："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMinor.inversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale(音階)について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType = scale.MajorScale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://web.mit.edu/music21/doc/moduleReference/moduleScale.html\n",
    "\n",
    "によれば\n",
    "\n",
    "ConcreteScale.derive(other, comparisonAttribute='pitchClass')\n",
    "\n",
    "Return the closest-matching ConcreteScale based on the pitch collection provided as a Stream, a ConcreteScale, or a list of Pitch objects.\n",
    "\n",
    "要は音階がドミソ（すべて白鍵）ならドレミファソラシド（すべて白鍵）が含まれているC Major音階と推定するような感じか。\n",
    "推定アルゴリズムは変化の可能性ありと公式ウェブにも書いてある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType.derive(cMinor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = scale.MinorScale().derive(cMinor)\n",
    "scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定されたscaleに含まれる音を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([pitch for pitch in scales.getPitches()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドリアンスケールの場合の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleType = scale.DorianScale()\n",
    "scales = scaleType.derive(cMinor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微分音（microtonal)\n",
    "\n",
    "参考URL:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Microtonal_music\n",
    "\n",
    "https://groups.google.com/forum/#!topic/music21list/-8PTr2gU8Hs\n",
    "\n",
    "http://web.mit.edu/music21/doc/moduleReference/modulePitch.html#music21.pitch.Pitch.convertMicrotonesToQuarterTones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他の基本的なscoreに対する操作(あまり必要ないかも)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.analyze('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tinynotationについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = converter.parse(\"tinynotation: 3/4 c4 d8 f g16 a g f#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = stream.Stream()\n",
    "s2.insert(0  , p)#adding part, first argument should be offset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=converter.parse(\"tinynotation: c4 d8 f g16 a g f#\")\n",
    "s2.insert(100,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=converter.parse(\"tinynotation: c4 d8 f g16 a g f#\")\n",
    "s2.insert(10,r)\n",
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.insert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?s2.insert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
