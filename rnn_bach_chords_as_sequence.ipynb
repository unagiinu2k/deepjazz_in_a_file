{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%bash\n",
    "git commit -a -m \"studying basic stats further  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.rileynwong.com/blog/2019/2/25/generating-music-with-an-lstm-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(l, n):\n",
    "    \"\"\"\n",
    "    リストをサブリストに分割する\n",
    "    :param l: リスト\n",
    "    :param n: サブリストの要素数\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    for idx in range(0, len(l), n):\n",
    "        yield l[idx:idx + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import score2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'score2df' from '/home/toshinao/PycharmProjects/deepjazz_in_a_file/score2df.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(score2df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 差分バージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_difference_based = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_discrete = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = str(is_difference_based) + \"_\"  + str(is_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = 'saved/seq_df_scores_{}.pkl'.format(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_use_preprocessed_df = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame()\n",
    "if is_use_preprocessed_df:\n",
    "    df_scores = pd.read_pickle(pkl_path)\n",
    "else:\n",
    "    for file in glob.glob(\"chorales/midi/*.mid\"):\n",
    "        print(file)\n",
    "        df_score = score2df.score2dataframe(file)\n",
    "        df_score = score2df.add_sequential_diffs(df_score)\n",
    "        df_score = df_score.assign(file = file)\n",
    "        df_scores = df_scores.append(df_score , ignore_index = True )\n",
    "        \n",
    "    df_scores.to_pickle(pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtを0か0.25だけにする(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = df_scores.assign(dt = np.where(df_scores.dt > 0.001 , 0.25 , df_scores.dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = df_scores.assign(dt = np.where(df_scores.dt > 2.0 , np.nan , df_scores.dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.dropna(subset = ['dcent', 'dt'] , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scores , aes(x = 'dt' , y = 'dcent' , color = 'n')) + geom_point() + theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scores.query('dt != 0') , aes(fill = 'n' , x = 'dcent / 100')) + geom_histogram() + theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_scores.query('abs(dcent/100)>20 & n != 0')['file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=converter.parse('chorales/midi/000101b_.mid').write('lily.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scores.query('dt == 0') , aes(fill = 'n' , x = 'dcent / 100')) + geom_histogram() + theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scores.query('dt == 0') , aes(color = 'n' , x = 'dcent')) + geom_histogram() + facet_wrap('~n') + theme_void()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_discrete:\n",
    "    dtype = str\n",
    "else:\n",
    "    dtype = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_list = []\n",
    "dt_list = []\n",
    "for f in set(df_scores.file):\n",
    "    df_file = df_scores[df_scores.file == f]\n",
    "\n",
    "    run_notes = df_file.dcent.astype(dtype)\n",
    "    run_dts = df_file.dt.astype(dtype)\n",
    "    for n in split_list(run_notes , max_sequence_length):\n",
    "        if len(n) > 10:\n",
    "            notes_list.append(n)\n",
    "    for n in split_list(run_dts , max_sequence_length):\n",
    "        if len(n) > 10:\n",
    "            dt_list.append(n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notes_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dt_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.statsmodels.org/dev/example_formulas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = 'dcent ~ dt' , data = df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-pack procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with label encoding (for discrete version)\n",
    "https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
    "に概ね準拠仕様と思ったが・・・\n",
    "\n",
    "- そもそもlabelencoder -> onehot  は今後必要ないよとwarning が出る\n",
    "- onehot の挙動が読みにくい\n",
    "\n",
    "のでlabelencodingしたあと直にnp.arrayをmanual onehote化したほうがいいのではないか？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_y1, raw_X1 , le1 = score2df.yx_encoder(notes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_y2, raw_X2 , le2 = score2df.yx_encoder(dt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = [torch.cat((raw_X1[i] , raw_X2[i]) , 1) for i in range(len(raw_X1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad and pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_X = torch.nn.utils.rnn.pack_sequence(raw_X , enforce_sorted=False)\n",
    "\n",
    "ppd_X = torch.nn.utils.rnn.pad_packed_sequence(packed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_y1 = torch.nn.utils.rnn.pack_sequence(raw_y1 , enforce_sorted=False)\n",
    "\n",
    "ppd_y1 = torch.nn.utils.rnn.pad_packed_sequence(packed_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "packed_y2 = torch.nn.utils.rnn.pack_sequence(raw_y2 , enforce_sorted=False)\n",
    "\n",
    "ppd_y2 = torch.nn.utils.rnn.pad_packed_sequence(packed_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference\n",
    "\n",
    "- [OneHotEncoderだけでいける。LabelEncoderをかます必要なし]と当初思っていたがむしろ逆\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n",
    "\n",
    "Another possible good reference:\n",
    "https://stackoverflow.com/questions/30869382/encoding-string-to-numbers-so-as-to-use-it-in-scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.Tensor([len(x) - 1 for x in notes_list])\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ppd_X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM\n",
    "\n",
    "参考文献のpreprocessはあまり納得いかないので・・\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "をみつつやってみるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献に似せたモデル\n",
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "に似せたモデル\n",
    "\n",
    "\n",
    "softmaxを二重にかけないように注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size1 , input_size2, hidden_size, num_layers , dropout):\n",
    "        #super(my_model, self).__init__()\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        input_size = input_size1 + input_size2\n",
    "        \n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers , dropout=dropout)\n",
    "\n",
    "        self.linear1 = nn.Linear(hidden_size, input_size1) #output dimension has to be identical with the input dimension\n",
    "        \n",
    "        self.linear2 = nn.Linear(hidden_size, input_size2) #output dimension has to be identical with the input dimension\n",
    " \n",
    "        self.linear1b = nn.Linear(input_size1, input_size1) #output dimension has to be identical with the input dimension\n",
    "        \n",
    "        self.linear2b = nn.Linear(input_size2, input_size2) #output dimension has to be identical with the input dimension\n",
    "  \n",
    "     \n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        #self.h0 = torch.randn(self.num_layers , sequence_num , self.hidden_size)\n",
    "        #self.c0 = torch.randn(self.num_layers , sequence_num, self.hidden_size)\n",
    "        y, (hn, cn) = self.rnn(input)#, (self.h0, self.c0))\n",
    "        y1 = self.linear1(y)\n",
    "        y1 = self.relu(y1)\n",
    "        y1 = self.linear1b(y1)\n",
    "        y2 = self.linear2(y)\n",
    "        y2 = self.relu(y2)\n",
    "        y2 = self.linear2b(y2)\n",
    "       \n",
    "        return y1,y2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size1 = raw_X1[0].shape[1]\n",
    "input_size2 = raw_X2[0].shape[1]\n",
    "hidden_size = 512 \n",
    "num_layers = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size1 , input_size2 , hidden_size , num_layers , dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp1 ,y_tmp2 = model.forward(ppd_X[0][:, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    連続バージョン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/49040180/change-tanh-activation-in-lstm-to-relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        \"\"\"\"Constructor of the class\"\"\"\n",
    "        super(LSTMCell, self).__init__()\n",
    "\n",
    "        self.nlayers = nlayers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        ih, hh = [], []\n",
    "        for i in range(nlayers):\n",
    "            ih.append(nn.Linear(input_size, 4 * hidden_size))\n",
    "            hh.append(nn.Linear(hidden_size, 4 * hidden_size))\n",
    "        self.w_ih = nn.ModuleList(ih)\n",
    "        self.w_hh = nn.ModuleList(hh)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"\"Defines the forward computation of the LSTMCell\"\"\"\n",
    "        hy, cy = [], []\n",
    "        for i in range(self.nlayers):\n",
    "            hx, cx = hidden[0][i], hidden[1][i]\n",
    "            gates = self.w_ih[i](input) + self.w_hh[i](hx)\n",
    "            i_gate, f_gate, c_gate, o_gate = gates.chunk(4, 1)\n",
    "\n",
    "            i_gate = F.sigmoid(i_gate)\n",
    "            f_gate = F.sigmoid(f_gate)\n",
    "            c_gate = F.tanh(c_gate)\n",
    "            o_gate = F.sigmoid(o_gate)\n",
    "\n",
    "            ncx = (f_gate * cx) + (i_gate * c_gate)\n",
    "            nhx = o_gate * F.tanh(ncx)\n",
    "            cy.append(ncx)\n",
    "            hy.append(nhx)\n",
    "            input = self.dropout(nhx)\n",
    "\n",
    "        hy, cy = torch.stack(hy, 0), torch.stack(cy, 0)\n",
    "        return hy, cy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# criterion (cross entropy lossはlog softmaxを含んでいるので二重に作用させないよう注意が必要）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy for one-hot representation\n",
    "https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/4\n",
    "\n",
    "one-hotのままでなくて、Rでいうところのfactorに戻したほうがよさそう（？）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "input has to be a Tensor of size either (minibatch, C)(minibatch,C) or (minibatch, C, d_1, d_2, ..., d_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_use_gpu = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and is_use_gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ppd_X[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sample size : {}\".format(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = range( 0 ,sample_size ,  batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses1 = []\n",
    "losses2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_when_random1 = 1 /input_size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_when_random2 = 1 / input_size2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'saved/model20191124_{}'.format(id)\n",
    "\n",
    "#model_path = 'saved/model20191125_{}'.format(id)\n",
    "\n",
    "# model_path = 'saved/model20191207_{}'.format(id)\n",
    "\n",
    "\n",
    "#model_path = 'saved/model20191208b_{}'.format(id)\n",
    "\n",
    "\n",
    "\n",
    "#model_path = 'saved/model20191221_{}'.format(id)\n",
    "model_path = 'saved/model20191226_{}'.format(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "for k in range(n_epochs):\n",
    "    batch_loss1 = 0\n",
    "    batch_loss2 = 0\n",
    "\n",
    "    shuffled_idx = torch.randperm(sample_size)\n",
    "    for i in batch_indices:\n",
    "        #display(\".\")\n",
    "        batch_samples = shuffled_idx[i:min(i + batch_size , sample_size) ]\n",
    "\n",
    "        loss1, loss2 = score2df.batch_loss_2vars(ppd_y1, ppd_y2 , ppd_X , mask , batch_samples , device , model , criterion)\n",
    "        batch_loss1 += loss1.item()\n",
    "        batch_loss2 += loss2.item()\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    batch_loss1 /= torch.sum(mask).item()\n",
    "    losses1.append(batch_loss1)\n",
    "    mean_correct_prob1 = np.exp(-batch_loss1)\n",
    "    batch_loss2 /= torch.sum(mask).item()\n",
    "    losses2.append(batch_loss2)\n",
    "    mean_correct_prob2 = np.exp(-batch_loss2)    \n",
    "    if k % 10 == 0:\n",
    "        torch.save(model.state_dict() , model_path)\n",
    "        display(\"epoch : {}\".format(k))\n",
    "        display(\"  [dcent] loss : {}   correct prob : {} correct / random : {}\".format(batch_loss1 ,\n",
    "                                                                        mean_correct_prob1 ,\n",
    "                                                                        mean_correct_prob1 / prob_when_random1))\n",
    "        \n",
    "        display(\"  [dt] loss : {}   correct prob : {} correct / random : {}\".format(batch_loss2 ,\n",
    "                                                                        mean_correct_prob2 ,\n",
    "                                                                        mean_correct_prob2 / prob_when_random2))\n",
    "\n",
    "model.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/jyori112/items/aad5703c1537c0139edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(input_size1 , input_size2 , hidden_size , num_layers , dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check errors using plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(pd.DataFrame({'n':range(len(losses1)) , 'loss':losses1}) , aes(x = 'n' , y ='loss')) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predicted vs realized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1, y_pred2 = model(ppd_X[0].to(cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter = score2df.predicted_vs_realized(y_pred1 , ppd_y1 , le1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scatter , aes(x = 'pred', y = 'realized')) + geom_point() + theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter2 = score2df.predicted_vs_realized(y_pred2 , ppd_y2 , le2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scatter2.query('pred == 0.0') , aes(x = 'realized' , color = \"pred\")) + geom_histogram() + scale_y_log10()# + facet_wrap('~pred' , scales = 'free') + theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scatter2 , aes(x = 'realized' , color = \"pred\")) + \\\n",
    "geom_histogram() + scale_y_log10(breaks = range(10)) \\\n",
    "+ facet_wrap('~pred') \\\n",
    "+ coord_flip()\\\n",
    "+ scale_x_continuous(breaks = [i  for i in range(60)]) + theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scatter2.query('pred in [0,0.25,0.5,0.75,1]') , aes(x = 'realized' , color = \"pred\")) + \\\n",
    "geom_histogram() + scale_y_log10() \\\n",
    "+ facet_wrap('~pred') \\\n",
    "+ coord_flip()\\\n",
    "+ scale_x_continuous(breaks = [i / 5 for i in range(60)]) + theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_scatter2 , aes(x = 'pred', y = 'realized')) + geom_point() + theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = np.zeros(input_size1 + input_size2 , dtype = \"float32\")\n",
    "x_gen[0] = 1.\n",
    "x_gen[input_size1 + 1] = 1.\n",
    "\n",
    "x_gen = x_gen.reshape([1,1,-1])\n",
    "x_gen = torch.tensor(x_gen).to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitalize(x1 , x2):\n",
    "    x_gen = np.zeros(input_size1 + input_size2 , dtype = \"float32\")\n",
    "    x_gen[0] = x1[-1].detach().numpy().argmax(axis = 1)[0]\n",
    "    x_gen[input_size1 + x2[-1].detach().numpy().argmax(axis = 1)[0]] = 1.\n",
    "    x_gen = x_gen.reshape([1,1,-1])\n",
    "    x_gen = torch.tensor(x_gen)\n",
    "    return x_gen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_gen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_gen):    \n",
    "    if i % 10 ==0:\n",
    "        display(i)\n",
    "    x1, x2 = model.forward(x_gen)\n",
    "    #x12 = torch.cat((x1 , x2) , dim = 2)\n",
    "    x_gen = torch.cat([x_gen, digitalize(x1 ,x2)] , dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%# old\n",
    "for i in range(N_gen):    \n",
    "    if i % 10 ==0:\n",
    "        display(i)\n",
    "    x1, x2 = model.forward(x_gen)\n",
    "    x12 = torch.cat((x1 , x2) , dim = 2)\n",
    "    x_gen = torch.cat([x_gen, x12[-1:]] , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternative generation method(not working yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一番後ろだけアップデートするのでなく、まるごと（最初以外）置き換える手法も試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_model(\n",
       "  (relu): ReLU()\n",
       "  (rnn): LSTM(109, 512, num_layers=2, dropout=0.1)\n",
       "  (linear1): Linear(in_features=512, out_features=107, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (linear1b): Linear(in_features=107, out_features=107, bias=True)\n",
       "  (linear2b): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = np.zeros(input_size1 + input_size2 , dtype = \"float32\")\n",
    "x_gen[0] = 1.\n",
    "x_gen[input_size1 + 1] = 1.\n",
    "\n",
    "x_gen = x_gen.reshape([1,1,-1])\n",
    "x_gen = torch.tensor(x_gen).to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitalize2(x1 , x2):\n",
    "    #x_gen = np.zeros(input_size1 + input_size2 , dtype = \"float32\")\n",
    "    x_gen1 = x1.detach().argmax(dim = 2)\n",
    "    x_gen2 = x2.detach().argmax(dim = 2)\n",
    "    n = x_gen1.shape[0]\n",
    "    x_gen = torch.zeros([n , 1 , input_size1 + input_size2])\n",
    "    for i in range(n):\n",
    "        #Pdb().set_trace()\n",
    "        x_gen[i,0,x_gen1[i,0].item()] = 1\n",
    "        x_gen[i,0,input_size1 + x_gen2[i,0].item()] = 1\n",
    "    #x_gen = torch.cat([x_gen1, x_gen2] ,dim = 2)\n",
    "    #x_gen[input_size1 + x2[-1].detach().numpy().argmax(axis = 1)[0]] = 1.\n",
    "    #x_gen = x_gen.reshape([1,1,-1])\n",
    "    #x_gen = torch.tensor(x_gen)\n",
    "    return x_gen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_gen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(N_gen):    \n",
    "    if i % 10 ==0:\n",
    "        display(i)\n",
    "    x1, x2 = model.forward(x_gen)\n",
    "    #x12 = torch.cat((x1 , x2) , dim = 2)\n",
    "    x_gen = torch.cat([x_gen[0:1] , digitalize2(x1, x2)] , dim =0)\n",
    "    #x_gen = torch.cat([x_gen[0:1] , torch.cat([x1, x2] , dim = 2)] , dim =0)\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previous (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = np.zeros(input_size , dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen[0] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = x_gen.reshape([1,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = torch.tensor(x_gen).to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_gen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_gen):    \n",
    "    x1 = model.forward(x_gen)\n",
    "    x_gen = torch.cat([x_gen[:1] , x1] , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_gen = x_gen.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx1_gen = nx_gen[:,:,range(input_size1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx2_gen = nx_gen[:,:,range(input_size1,  input_size1 + input_size2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xidx1_gen = nx1_gen.argmax(axis = 2).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xidx2_gen = nx2_gen.argmax(axis = 2).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift1_gen= np.array( [float(le1.classes_[xidx1_gen[i]]) for i in range(xidx1_gen.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift2_gen= np.array( [float(le2.classes_[xidx2_gen[i]]) for i in range(xidx2_gen.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt = 0.5\n",
    "run_t = 0\n",
    "base_note = note.Note(\"C5\")\n",
    "run_note = base_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_notes = []\n",
    "#for i in range(15): #range(shift1_gen.shape[0]):\n",
    "for i in range(shift1_gen.shape[0]):\n",
    "    if i % 10 == 0:\n",
    "        pass#display(i)\n",
    "    \n",
    "    run_shift = int(shift1_gen[i] / 100)\n",
    "    run_dt = shift2_gen[i]\n",
    "    display(run_dt)\n",
    "    run_t = run_t + run_dt\n",
    "    if i >= 57:\n",
    "        pass #Pdb().set_trace()\n",
    "    if run_dt != 0.:\n",
    "        if i !=0: #len(run_notes) != 0:\n",
    "            #display(\",\".join([x.nameWithOctave for x in run_notes]))\n",
    "            st1.insert(run_t , chord.Chord(run_notes))\n",
    "            display(run_notes)\n",
    "            run_notes = []            \n",
    "        if run_shift == 0:\n",
    "            run_note = base_note\n",
    "        else:                                      \n",
    "            #run_note = base_note.transpose(interval.ChromaticInterval(run_shift))\n",
    "            run_note = interval.ChromaticInterval(run_shift).transposeNote(base_note)\n",
    "        base_note = run_note\n",
    "        #run_note = base_note\n",
    "        run_notes = [run_note]\n",
    "    else:\n",
    "        if run_shift != 0.:            \n",
    "            #run_note = run_note.transpose(interval.ChromaticInterval(run_shift))\n",
    "            run_note = interval.ChromaticInterval(run_shift).transposeNote(run_note)\n",
    "        run_notes.append(run_note)\n",
    "        \n",
    "    #   if run_dt != 0 or run_shift !=0:            \n",
    "    #st1.insert(run_t , run_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=st1.write('lily.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.write('midi', fp ='tmp/rnn_generated_1221.midi' )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## playing sound (fail)\n",
    "\n",
    "jupyter lab上でのmidiファイル再生はいまのところできていない。一度ファイルに落として、jupyter notebook(labではなく）でplay_sound.ipynbで確認するのが現段階での最善手\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "freq = 44100    # audio CD quality\n",
    "bitsize = -16   # unsigned 16 bit\n",
    "channels = 2    # 1 is mono, 2 is stereo\n",
    "buffer = 1024    # number of samples\n",
    "pygame.mixer.init(freq, bitsize, channels, buffer)\n",
    "pygame.mixer.music.set_volume(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = midi.realtime.StreamPlayer(st1)\n",
    "sp.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st2 = stream.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st2.insert(0 , chord.Chord([note.Note('C5') , note.Note('D5'), note.Note('F5') ,note.Note('F6'),note.Note('A7')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st2.insert(0 , chord.Chord([note.Note('C5')])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st2.insert(0 , chord.Chord(run_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=st2.write('lily.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 比較用にlinear modelを用いてgenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_gen = [800,200,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_gen = 100\n",
    "\n",
    "noise_strength = 0.1 #1にするとmseの誤差項の大きさをそのまま使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_gen):\n",
    "    df_gen = pd.DataFrame({'dcent_lag1':[sequence_gen[-1]] , 'dcent_lag2':[sequence_gen[-2]] , 'dcent_lag3':[sequence_gen[-3]]})\n",
    "    sequence_gen.append(int(res.predict(df_gen + noise_strength * np.sqrt(res.mse_resid) * np.random.normal()) / 100) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence_gen[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_cumsum_gen = np.array(sequence_gen).cumsum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=stream.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.5\n",
    "base_note = note.Note(\"C5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(shift_cumsum_gen.shape[0]):\n",
    "    run_shift = int(shift_cumsum_gen[i] / 100)\n",
    "    run_dt = int()\n",
    "    if run_shift == 0:\n",
    "        run_note = base_note\n",
    "    else:                                      \n",
    "        run_note = base_note.transpose(interval.ChromaticInterval(run_shift))\n",
    "    st1.insert(0.5 * i , run_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shift == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=st1.write('lily.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.write('midi', fp ='tmp/tmp.midi' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = note.Note(\"D5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.transpose(interval.GenericInterval(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat([x0, x1] , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[-2:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat([x, x2[-2:-1]] , dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my own try and error　（この節のプロセスは必要ない）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting the note...\n",
    "Useful tips for jupyter notebook:\n",
    "\n",
    "https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://d.hatena.ne.jp/naraba/20121201/p1\n",
    "#http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html\n",
    "\n",
    "from music21 import *\n",
    "#environment.set('musicxmlPath' , r\"C:\\Program Files (x86)\\Finale NotePad 2012\\Finale NotePad.exe\")\n",
    "#configure.run()\n",
    "#environment.keys()\n",
    "#environment.get('musicxmlPath')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "楽譜を表示するためのおまじない\n",
    "\n",
    "参考URL:https://groups.google.com/forum/#!topic/music21list/FmU6HeNm7AM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = environment.UserSettings() #不必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'\n",
    "us['musescoreDirectPNGPath'] = r'C:\\Program Files (x86)\\MuseScore 2\\bin\\MuseScore.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install musescore in linux (apt-getでインストールするのがポイント）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all those who will struggle with displaying scores from music21 within Jupyter Notebook on Linux (e.g. Ubuntu), follow these steps:\n",
    "https://stackoverflow.com/questions/49939275/python-music21-library-create-png-from-stream/49945456#49945456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MuseScoreのバージョンが2から3にあがっていたので、初期設定のままではうごきませんでした。\n",
    "https://qiita.com/nofrmm/items/c3662555b145f6b42d92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set(\"musescoreDirectPNGPath\", \"/usr/bin/musescore\")\n",
    "#environment.set(\"musicxmlPath\", \"/snap/bin/musescore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#us.create()\n",
    "us['musicxmlPath'] = r'/snap/bin/musescore.mscore'\n",
    "us['musescoreDirectPNGPath'] = r'/snap/bin/musescore.mscore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext music21.ipython21　#不必要"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
